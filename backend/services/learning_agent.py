"""
Learning Agent - Unified AI Agent for Document-based Learning

Combines:
- Document search tools (Calculator, Wikipedia, Python REPL, User Documents)
- ReAct reasoning pattern (Thought ‚Üí Action ‚Üí Observation ‚Üí Answer)
- Intent classification and conversation handling

Simplified architecture - everything in one place for easier maintenance.
"""

import os
import logging
import asyncio
import re
import json
import numexpr
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session

# LangChain imports
from langchain_core.tools import Tool
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from pydantic import BaseModel, Field

from db import models
from services.llm_provider import get_llm_provider
from core.metrics import track_tokens
from core.cloudwatch_metrics import track_llm_tokens

logger = logging.getLogger(__name__)


# ============================================================================
# PART 1: AGENT TOOLS
# ============================================================================

class CalculatorInput(BaseModel):
    """Input for calculator tool"""
    expression: str = Field(description="A mathematical expression to evaluate, e.g. '2+2', '3.5*4', 'sqrt(16)'")


class DocumentSearchInput(BaseModel):
    """Input for document search tool"""
    query: str = Field(description="The search query to find relevant information in user's uploaded documents")
    subject: Optional[str] = Field(default=None, description="Optional subject filter")


class PythonReplInput(BaseModel):
    """Input for Python REPL"""
    code: str = Field(description="Valid Python code to execute. Can use numpy, scipy, math libraries.")


def create_calculator_tool(websocket_callback=None):
    """Create calculator tool with WebSocket status updates"""
    
    async def calculator_func_async(expression: str) -> str:
        """Evaluate a mathematical expression safely using numexpr"""
        try:
            # Tool progress updates are separate from reasoning steps
            if websocket_callback:
                await websocket_callback({
                    'type': 'tool_progress',
                    'tool': 'Calculator',
                    'message': f'üßÆ ƒêang t√≠nh to√°n: {expression}'
                })
            
            result = numexpr.evaluate(expression).item()
            
            if websocket_callback:
                await websocket_callback({
                    'type': 'tool_progress',
                    'tool': 'Calculator',
                    'message': f'‚úÖ K·∫øt qu·∫£: {result}'
                })
            
            return f"Result: {result}"
        except Exception as e:
            if websocket_callback:
                await websocket_callback({
                    'type': 'tool_progress',
                    'tool': 'Calculator',
                    'message': f'‚ö†Ô∏è L·ªói t√≠nh to√°n: {str(e)}'
                })
            return f"Error: Invalid expression - {str(e)}"
    
    return Tool(
        name="Calculator",
        description="Useful for mathematical calculations. Input should be a valid mathematical expression like '2+2' or 'sqrt(144)'",
        func=calculator_func_async,
        args_schema=CalculatorInput
    )


def create_wikipedia_tool(websocket_callback=None):
    """Create Wikipedia tool with WebSocket status updates"""
    wikipedia_wrapper = WikipediaAPIWrapper(
        top_k_results=2,
        doc_content_chars_max=2000,
        lang="vi"
    )
    
    async def wikipedia_search(query: str) -> str:
        """Search Wikipedia with status updates"""
        try:
            if websocket_callback:
                await websocket_callback({
                    'type': 'tool_progress',
                    'tool': 'Wikipedia',
                    'message': f'üåê ƒêang t√¨m ki·∫øm tr√™n Wikipedia: "{query[:50]}..."'
                })
            
            result = wikipedia_wrapper.run(query)
            
            if websocket_callback:
                await websocket_callback({
                    'type': 'tool_progress',
                    'tool': 'Wikipedia',
                    'message': f'‚úÖ T√¨m th·∫•y th√¥ng tin t·ª´ Wikipedia'
                })
            
            return result
        except Exception as e:
            if websocket_callback:
                await websocket_callback({
                    'type': 'tool_progress',
                    'tool': 'Wikipedia',
                    'message': f'‚ö†Ô∏è L·ªói t√¨m ki·∫øm Wikipedia: {str(e)}'
                })
            return f"Error searching Wikipedia: {str(e)}"
    
    return Tool(
        name="Wikipedia",
        description="Useful for looking up general knowledge, historical facts, scientific concepts, geography, etc. Input should be a search query in Vietnamese or English.",
        func=wikipedia_search
    )


def create_user_doc_search_tool(db, user_id: int, structure_id: Optional[int] = None, websocket_callback=None):
    """Smart document search - returns RELEVANT sections based on query keywords"""
    
    def extract_keywords(text: str) -> List[str]:
        """Extract meaningful keywords from query (remove stop words)"""
        stop_words = {
            'l√†', 'g√¨', 'nh∆∞', 'th·∫ø', 'n√†o', 'c√≥', 'ƒë∆∞·ª£c', 'c·ªßa', 'v√†', 'hay',
            'cho', 'v·ªõi', 't·ª´', 'trong', 'v·ªÅ', 'b·∫±ng', 'ƒë·ªÉ', '·ªü', 't·∫°i', 'n√†y',
            'kia', 'ƒë√≥', 'm√†', 'th√¨', 'n·∫øu', 'v√¨', 'sao', 'ai', 'ƒë√¢u', 'n√™n'
        }
        words = text.lower().split()
        keywords = [w for w in words if len(w) > 2 and w not in stop_words]
        return keywords
    
    def calculate_relevance(paragraph: str, keywords: List[str]) -> float:
        """Calculate relevance score based on keyword density"""
        if not paragraph.strip():
            return 0.0
        
        para_lower = paragraph.lower()
        matches = sum(para_lower.count(kw) for kw in keywords)
        word_count = len(paragraph.split())
        
        # Relevance = (matches * 100) / word_count
        # Boost score if multiple keywords appear
        density = (matches * 100) / max(word_count, 1)
        
        return density
    
    async def search_user_docs(query: str, subject: Optional[str] = None) -> str:
        """Search in user's uploaded documents using keyword relevance"""
        try:
            if websocket_callback:
                await websocket_callback({
                    'type': 'tool_progress',
                    'tool': 'SearchUserDocuments',
                    'message': f'üîç ƒêang t√¨m ki·∫øm trong t√†i li·ªáu: "{query[:50]}..."'
                })
            
            logger.info(f"Searching documents for: {query}")
            
            # Get user's documents from uploaded_documents JSON field
            user = db.query(models.User).filter(models.User.id == user_id).first()
            
            if not user or not user.uploaded_documents:
                if websocket_callback:
                    await websocket_callback({
                        'type': 'tool_progress',
                        'tool': 'SearchUserDocuments',
                        'message': '‚ùå B·∫°n ch∆∞a t·∫£i l√™n t√†i li·ªáu n√†o'
                    })
                return "B·∫°n ch∆∞a t·∫£i l√™n t√†i li·ªáu n√†o. H√£y upload t√†i li·ªáu tr∆∞·ªõc khi ƒë·∫∑t c√¢u h·ªèi."
            
            documents = user.uploaded_documents
            logger.info(f"Found {len(documents)} documents for user {user_id}")
            
            # Extract keywords from query
            query_keywords = extract_keywords(query)
            logger.info(f"Query keywords: {query_keywords}")
            
            if not query_keywords:
                # Fallback to first document if no keywords
                if documents and documents[0].get('content'):
                    content = documents[0]['content'][:3000]
                    return f"[T√†i li·ªáu: {documents[0].get('filename', 'Unknown')}]\n{content}"
                return "Kh√¥ng th·ªÉ tr√≠ch xu·∫•t t·ª´ kh√≥a t·ª´ c√¢u h·ªèi."
            
            # Score all paragraphs across all documents
            relevant_sections = []
            
            for doc in documents:
                content = doc.get('content', '')
                if not content:
                    continue
                
                filename = doc.get('filename', 'Unknown')
                
                # Split into paragraphs (by double newline or single newline)
                paragraphs = re.split(r'\n\n+|\n', content)
                
                for para in paragraphs:
                    para = para.strip()
                    if len(para) < 50:  # Skip very short paragraphs
                        continue
                    
                    score = calculate_relevance(para, query_keywords)
                    
                    if score > 1.0:  # Threshold: at least 1% keyword density
                        relevant_sections.append({
                            'filename': filename,
                            'content': para,
                            'score': score
                        })
            
            if not relevant_sections:
                if websocket_callback:
                    await websocket_callback({
                        'type': 'tool_progress',
                        'tool': 'SearchUserDocuments',
                        'message': '‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu'
                    })
                return "Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu ƒë√£ t·∫£i l√™n."
            
            # Sort by relevance score and take top 3
            relevant_sections.sort(key=lambda x: x['score'], reverse=True)
            top_sections = relevant_sections[:3]
            
            if websocket_callback:
                await websocket_callback({
                    'type': 'tool_progress',
                    'tool': 'SearchUserDocuments',
                    'message': f'‚úÖ T√¨m th·∫•y {len(top_sections)} ƒëo·∫°n vƒÉn li√™n quan (t·ª´ {len(documents)} t√†i li·ªáu)'
                })
            
            # Format output with source info
            formatted = []
            for section in top_sections:
                # Limit each section to 1000 chars
                content = section['content'][:1000]
                if len(section['content']) > 1000:
                    content += "\n[...]"
                
                formatted.append(
                    f"[T√†i li·ªáu: {section['filename']}, Li√™n quan: {section['score']:.1f}%]\n{content}"
                )
            
            result = "\n\n---\n\n".join(formatted)
            logger.info(f"Returning {len(formatted)} relevant sections ({len(result)} chars total)")
            return result
            
        except Exception as e:
            logger.error(f"Error searching docs: {e}")
            if websocket_callback:
                await websocket_callback({
                    'type': 'tool_progress',
                    'tool': 'SearchUserDocuments',
                    'message': f'‚ö†Ô∏è L·ªói: {str(e)}'
                })
            return f"L·ªói khi t√¨m ki·∫øm: {str(e)}"
    
    return Tool(
        name="SearchUserDocuments",
        description="‚≠ê LU√îN S·ª¨ D·ª§NG ƒê·∫¶U TI√äN - T√¨m ki·∫øm trong t√†i li·ªáu user ƒë√£ upload. ∆Øu ti√™n s·ª≠ d·ª•ng th√¥ng tin t·ª´ ƒë√¢y tr∆∞·ªõc khi d√πng c√¥ng c·ª• kh√°c.",
        func=search_user_docs,
        args_schema=DocumentSearchInput
    )


def create_python_repl_tool(websocket_callback=None):
    """Create Python REPL tool with WebSocket status updates"""
    
    async def python_repl_func(code: str) -> str:
        """Execute Python code safely (with restrictions)"""
        try:
            if websocket_callback:
                await websocket_callback({
                    'type': 'tool_progress',
                    'tool': 'PythonREPL',
                    'message': f'üêç ƒêang th·ª±c thi Python code...'
                })
            
            import math
            import numpy as np
            import scipy
            
            namespace = {
                'math': math,
                'np': np,
                'scipy': scipy,
                '__builtins__': {
                    'abs': abs,
                    'round': round,
                    'sum': sum,
                    'len': len,
                    'max': max,
                    'min': min,
                    'range': range,
                    'list': list,
                    'dict': dict,
                    'str': str,
                    'int': int,
                    'float': float,
                    'print': print
                }
            }
            
            exec(code, namespace)
            
            if 'result' in namespace:
                if websocket_callback:
                    await websocket_callback({
                        'type': 'tool_progress',
                        'tool': 'PythonREPL',
                        'message': f'‚úÖ Code th·ª±c thi th√†nh c√¥ng'
                    })
                return f"Result: {namespace['result']}"
            else:
                return "Code executed successfully (no 'result' variable found)"
                
        except Exception as e:
            if websocket_callback:
                await websocket_callback({
                    'type': 'tool_progress',
                    'tool': 'PythonREPL',
                    'message': f'‚ö†Ô∏è L·ªói th·ª±c thi code: {str(e)}'
                })
            return f"Error executing code: {str(e)}"
    
    return Tool(
        name="PythonREPL",
        description="Execute Python code for complex calculations. Use this when Calculator is not enough. Store final result in 'result' variable.",
        func=python_repl_func,
        args_schema=PythonReplInput
    )


def get_agent_tools(db, user_id: int, structure_id: Optional[int] = None, websocket_callback=None) -> List[Tool]:
    """Get all available tools for the ReAct agent"""
    tools = [
        create_user_doc_search_tool(db, user_id, structure_id, websocket_callback),
        create_calculator_tool(websocket_callback),
        create_python_repl_tool(websocket_callback),
        create_wikipedia_tool(websocket_callback)
    ]
    
    logger.info(f"Initialized {len(tools)} tools for user {user_id}")
    return tools


# ============================================================================
# PART 2: REACT AGENT
# ============================================================================

class ReActLearningAgent:
    """ReAct Agent for learning mode - Combines reasoning with tool usage"""
    
    def __init__(self, db, user_id: int, structure_id: Optional[int] = None, websocket_callback=None):
        self.db = db
        self.user_id = user_id
        self.structure_id = structure_id
        self.websocket_callback = websocket_callback
        
        api_key = os.getenv("LLM_API_KEY")
        model_name = os.getenv("LLM_MODEL", "gemini-2.0-flash-exp")
        
        self.llm = ChatGoogleGenerativeAI(
            model=model_name,
            google_api_key=api_key,
            temperature=0.2,
            convert_system_message_to_human=True
        )
        
        self.tools = get_agent_tools(db, user_id, structure_id, websocket_callback)
        self.tool_map = {tool.name: tool for tool in self.tools}
        
        logger.info(f"ReAct Agent initialized for user {user_id} with {len(self.tools)} tools")
    
    def _get_tool_descriptions(self) -> str:
        """Format tool descriptions for prompt"""
        descriptions = []
        for tool in self.tools:
            descriptions.append(f"- {tool.name}: {tool.description}")
        return "\n".join(descriptions)
    
    async def solve(self, query: str, conversation_history: Optional[List[Dict]] = None) -> Dict[str, Any]:
        """Solve a problem using ReAct reasoning loop"""
        try:
            logger.info(f"[ReAct Agent] Processing query: {query[:100]}...")
            
            reasoning_steps = []
            tools_used = set()
            max_iterations = 5
            
            system_prompt = f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω h·ªçc t·∫≠p th√¥ng minh s·ª≠ d·ª•ng ReAct + Self-Reflection.

B·∫†N C√ì C√ÅC C√îNG C·ª§ SAU:
{self._get_tool_descriptions()}

üìã QUY T·∫ÆC X·ª¨ L√ù:

1. **B∆Ø·ªöC 1 (ƒê√É T·ª∞ ƒê·ªòNG)**: T√¨m ki·∫øm t√†i li·ªáu c·ªßa user - Xem k·∫øt qu·∫£ trong Observation ƒë·∫ßu ti√™n

2. **PH√ÇN T√çCH K·∫æT QU·∫¢ T√ÄI LI·ªÜU**:
   - N·∫øu t√†i li·ªáu c√≥ ƒê·ªäNH NGHƒ®A, GI·∫¢I TH√çCH CHI TI·∫æT v·ªÅ c√¢u h·ªèi ‚Üí ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng
   - N·∫øu t√†i li·ªáu ch·ªâ NH·∫ÆC T√äN/ƒê·ªÄ C·∫¨P m√† kh√¥ng gi·∫£i th√≠ch ‚Üí C·∫ßn search Wikipedia
   - N·∫øu user Y√äU C·∫¶U T√åM TH√äM ("t√¨m th√¥ng tin", "tra c·ª©u") ‚Üí Ph·∫£i search Wikipedia

3. **ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG (Self-Evaluation)**:
   Sau m·ªói Observation, B·∫ÆT BU·ªòNG ƒë√°nh gi√°:
   
   Self-Evaluation:
   - C√≥ ƒë·ªß th√¥ng tin? [Yes/No]
   - ƒê·ªô ch√≠nh x√°c: [High/Medium/Low]
   - Thi·∫øu g√¨: [n·∫øu c√≥]
   
   **Quy·∫øt ƒë·ªãnh:**
   - N·∫øu ƒë·ªô ch√≠nh x√°c = High V√Ä ƒë·ªß th√¥ng tin ‚Üí Final Answer
   - N·∫øu ƒë·ªô ch√≠nh x√°c < High HO·∫∂C thi·∫øu th√¥ng tin ‚Üí Ti·∫øp t·ª•c t√¨m ki·∫øm

4. **KHI N√ÄO D√ôNG WIKIPEDIA**:
   ‚úÖ T√†i li·ªáu ch·ªâ ƒë·ªÅ c·∫≠p t√™n m√† kh√¥ng gi·∫£i th√≠ch kh√°i ni·ªám
   ‚úÖ User h·ªèi ƒë·ªãnh nghƒ©a m√† t√†i li·ªáu kh√¥ng c√≥
   ‚úÖ User y√™u c·∫ßu t√¨m th√™m th√¥ng tin
   ‚úÖ C·∫ßn th√¥ng tin t·ªïng qu√°t m√† t√†i li·ªáu kh√¥ng ƒë·ªß
   
5. **Calculator/PythonREPL**: Ch·ªâ d√πng khi c·∫ßn t√≠nh to√°n

üìù FORMAT C√îNG TH·ª®C TO√ÅN:
- Inline: $...$ (VD: $x^2 + y^2 = z^2$)
- Block: $$...$$ 
- Ph√¢n s·ªë: $\\frac{{a}}{{b}}$, CƒÉn: $\\sqrt{{x}}$

üìå FORMAT TR·∫¢ L·ªúI:

Thought: [Ph√¢n t√≠ch c√¢u h·ªèi]
Action: [Tool name]
Action Input: [input cho tool]
...
Observation: [K·∫øt qu·∫£ t·ª´ tool]

Self-Evaluation:
- C√≥ ƒë·ªß th√¥ng tin? [Yes/No]
- ƒê·ªô ch√≠nh x√°c: [High/Medium/Low]
- Thi·∫øu g√¨: [n·∫øu c√≥]

[N·∫øu c·∫ßn ti·∫øp t·ª•c]
Thought: [Quy·∫øt ƒë·ªãnh t√¨m th√™m th√¥ng tin]
Action: [Tool ti·∫øp theo]
...

[Khi ƒë√£ ƒë·ªß th√¥ng tin v√† ch·∫•t l∆∞·ª£ng cao]
Final Answer: [C√¢u tr·∫£ l·ªùi chi ti·∫øt, c√≥ c·∫•u tr√∫c, d·ªÖ hi·ªÉu]

‚ö†Ô∏è QUAN TR·ªåNG: 
- B·∫ÆT BU·ªòC c√≥ Self-Evaluation sau m·ªói Observation
- Ch·ªâ ƒë∆∞a Final Answer khi ƒë·ªô ch√≠nh x√°c = High
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát
- B·∫ÆT BU·ªòC k·∫øt th√∫c b·∫±ng "Final Answer:" """

            messages = [SystemMessage(content=system_prompt)]
            if conversation_history:
                for msg in conversation_history[-20:]:
                    if msg['role'] == 'user':
                        messages.append(HumanMessage(content=msg['content']))
                    elif msg['role'] == 'assistant':
                        messages.append(AIMessage(content=msg['content']))
            
            messages.append(HumanMessage(content=f"Question: {query}"))
            
            # ========== B∆Ø·ªöC 0: T·ª∞ ƒê·ªòNG SEARCH DOCUMENTS TR∆Ø·ªöC ==========
            doc_search_result = None
            has_useful_content = False
            if 'SearchUserDocuments' in self.tool_map:
                try:
                    logger.info("[ReAct Agent] Auto-searching user documents first...")
                    
                    # Execute document search FIRST (kh√¥ng emit executing)
                    search_tool = self.tool_map['SearchUserDocuments']
                    import inspect
                    if inspect.iscoroutinefunction(search_tool.func):
                        doc_search_result = await search_tool.func(query)
                    else:
                        doc_search_result = search_tool.func(query)
                    
                    tools_used.add('SearchUserDocuments')
                    
                    # Evaluate result
                    result_str = str(doc_search_result).strip()
                    has_useful_content = (
                        len(result_str) > 50 and 
                        'kh√¥ng t√¨m th·∫•y' not in result_str.lower() and
                        'ch∆∞a t·∫£i l√™n' not in result_str.lower()
                    )
                    
                    if has_useful_content:
                        status_msg = f"‚úÖ T√¨m th·∫•y {len(result_str)} k√Ω t·ª± t·ª´ t√†i li·ªáu c·ªßa b·∫°n"
                        result_quality = "good"
                    else:
                        status_msg = "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu"
                        result_quality = "not_found"
                    
                    # Emit CH·ªà 1 event completed (kh√¥ng emit executing ri√™ng)
                    if self.websocket_callback:
                        await self.websocket_callback({
                            'type': 'reasoning',
                            'step': 1,
                            'status': 'completed',
                            'description': status_msg,
                            'result_quality': result_quality,
                            'tool_name': 'T√¨m ki·∫øm t√†i li·ªáu ng∆∞·ªùi d√πng',
                            'tool_purpose': '∆Øu ti√™n t√¨m th√¥ng tin t·ª´ t√†i li·ªáu b·∫°n ƒë√£ t·∫£i l√™n',
                            'thought': 'B∆∞·ªõc ƒë·∫ßu ti√™n lu√¥n l√† t√¨m ki·∫øm trong t√†i li·ªáu c·ªßa ng∆∞·ªùi d√πng',
                            'action': 'SearchUserDocuments',
                            'action_input': query,
                            'observation': result_str[:500],
                            'result_length': len(result_str)
                        })
                    
                    reasoning_steps.append({
                        'tool': 'SearchUserDocuments',
                        'input': query,
                        'output': result_str[:500]
                    })
                    
                    # Add to conversation context
                    if has_useful_content:
                        messages.append(AIMessage(content=f"Thought: T√¥i s·∫Ω t√¨m ki·∫øm trong t√†i li·ªáu c·ªßa ng∆∞·ªùi d√πng tr∆∞·ªõc.\nAction: SearchUserDocuments\nAction Input: {query}"))
                        messages.append(HumanMessage(content=f"""Observation: {doc_search_result}

‚ö†Ô∏è QUAN TR·ªåNG: T√†i li·ªáu c·ªßa ng∆∞·ªùi d√πng ƒë√£ c√≥ {len(result_str)} k√Ω t·ª± th√¥ng tin li√™n quan!
D·ª±a tr√™n th√¥ng tin n√†y, h√£y t·ªïng h·ª£p c√¢u tr·∫£ l·ªùi CH·∫§T L∆Ø·ª¢NG CAO cho user:
- Gi·∫£i th√≠ch r√µ r√†ng, d·ªÖ hi·ªÉu
- C√≥ c·∫•u tr√∫c (bullet points n·∫øu c·∫ßn)
- D√πng c√¥ng th·ª©c LaTeX n·∫øu c√≥ to√°n h·ªçc: $...$
- Tr√≠ch d·∫´n ngu·ªìn t·ª´ t√†i li·ªáu khi ph√π h·ª£p

H√£y ƒë∆∞a ra Final Answer ngay."""))
                    
                    logger.info(f"[ReAct Agent] Document search result: {result_quality} ({len(result_str)} chars)")
                    
                except Exception as e:
                    logger.error(f"[ReAct Agent] Error in auto document search: {e}")
            
            # ========== TI·∫æP T·ª§C ReAct LOOP - LLM s·∫Ω synthesize response ==========
            start_step = 2 if doc_search_result else 1
            for iteration in range(max_iterations):
                logger.info(f"[ReAct Agent] Iteration {iteration + 1}/{max_iterations}")
                
                response = await self.llm.ainvoke(messages)
                response_content = response.content
                
                # Track token usage for learning agent
                if hasattr(response, 'response_metadata'):
                    metadata = response.response_metadata or {}
                    usage = metadata.get('usage_metadata', {})
                    prompt_tokens = usage.get('prompt_token_count', 0)
                    completion_tokens = usage.get('candidates_token_count', 0)
                    total_tokens = usage.get('total_token_count', 0)
                    if total_tokens > 0:
                        track_tokens(
                            provider='gemini',
                            model=self.llm.model,
                            prompt_tokens=prompt_tokens,
                            completion_tokens=completion_tokens,
                            total_tokens=total_tokens
                        )
                        track_llm_tokens(
                            provider='gemini',
                            model=self.llm.model,
                            prompt_tokens=prompt_tokens,
                            completion_tokens=completion_tokens,
                            total_tokens=total_tokens,
                            request_type='learning'
                        )
                
                if isinstance(response_content, list):
                    response_text = '\n\n'.join(str(item) for item in response_content)
                else:
                    response_text = str(response_content)
                
                logger.info(f"[ReAct Agent] LLM Response: {response_text[:200]}...")
                
                # Extract Thought
                thought_match = re.search(r'Thought:\s*(.+?)(?:\n|Action:|Final Answer:|$)', response_text, re.DOTALL)
                thought = thought_match.group(1).strip() if thought_match else ""
                
                # DETECT SELF-EVALUATION (after LLM sees Observation)
                if re.search(r'Self-Evaluation:', response_text, re.IGNORECASE):
                    logger.info(f"[ReAct] Self-Evaluation detected in step {iteration + 1}")
                    
                    eval_data = {'step': iteration + 1}
                    
                    # Parse components
                    enough_match = re.search(r'C√≥ ƒë·ªß th√¥ng tin\?[:\s]*\[?(Yes|No)\]?', response_text, re.IGNORECASE)
                    if enough_match:
                        eval_data['has_enough'] = enough_match.group(1)
                    
                    quality_match = re.search(r'ƒê·ªô ch√≠nh x√°c:[:\s]*\[?(High|Medium|Low)\]?', response_text, re.IGNORECASE)
                    if quality_match:
                        eval_data['quality'] = quality_match.group(1)
                    
                    missing_match = re.search(r'Thi·∫øu g√¨:[:\s]*(.+?)(?:\n|$)', response_text, re.DOTALL)
                    if missing_match:
                        eval_data['missing'] = missing_match.group(1).strip()[:100]
                    
                    # Emit self-reflection to frontend
                    if self.websocket_callback:
                        await self.websocket_callback({
                            'type': 'self_reflection',
                            **eval_data
                        })
                    
                    logger.info(f"[ReAct] Quality: {eval_data.get('quality', 'N/A')}, Enough: {eval_data.get('has_enough', 'N/A')}")
                
                # Check for Action FIRST (higher priority than Final Answer)
                action_match = re.search(r'Action:\s*(\w+)', response_text)
                
                # Only treat as Final Answer if NO Action present
                if "Final Answer:" in response_text and not action_match:
                    answer = response_text.split("Final Answer:")[-1].strip()
                    logger.info(f"[ReAct Agent] Final answer reached (no action)")
                    
                    # Send agent_complete with full answer
                    if self.websocket_callback:
                        await self.websocket_callback({
                            'type': 'agent_complete',
                            'status': 'completed',
                            'final_answer': answer
                        })
                    
                    return {
                        'answer': answer,
                        'reasoning_steps': reasoning_steps,
                        'tools_used': list(tools_used),
                        'success': True
                    }
                
                # Extract Action and Action Input
                action_match = re.search(r'Action:\s*(\w+)', response_text)
                input_match = re.search(r'Action Input:\s*(.+?)(?:\n|$)', response_text, re.DOTALL)
                
                if not action_match or not input_match:
                    logger.warning("[ReAct Agent] LLM didn't follow ReAct format")
                    
                    # Clean response
                    clean_response = response_text
                    if "Thought:" in clean_response:
                        parts = clean_response.split("Thought:")
                        if len(parts) > 1:
                            clean_response = parts[-1].strip()
                    
                    clean_response = re.sub(r'(üìö\s*)+', '', clean_response).strip()
                    
                    # Send agent_complete
                    if self.websocket_callback:
                        await self.websocket_callback({
                            'type': 'agent_complete',
                            'status': 'completed',
                            'final_answer': clean_response
                        })
                    
                    return {
                        'answer': clean_response,
                        'reasoning_steps': reasoning_steps,
                        'tools_used': list(tools_used),
                        'success': True
                    }
                
                action_name = action_match.group(1).strip()
                action_input = input_match.group(1).strip()
                
                # Tool descriptions for UI display
                tool_descriptions = {
                    'SearchUserDocuments': {
                        'name': 'T√¨m ki·∫øm t√†i li·ªáu ng∆∞·ªùi d√πng',
                        'purpose': 'T√¨m ki·∫øm th√¥ng tin trong c√°c t√†i li·ªáu ƒë√£ t·∫£i l√™n c·ªßa b·∫°n',
                        'action': 'ƒêang t√¨m ki·∫øm'
                    },
                    'Wikipedia': {
                        'name': 'Tra c·ª©u Wikipedia', 
                        'purpose': 'Tra c·ª©u ki·∫øn th·ª©c t·ªïng qu√°t tr√™n Wikipedia',
                        'action': 'ƒêang tra c·ª©u'
                    },
                    'Calculator': {
                        'name': 'M√°y t√≠nh',
                        'purpose': 'Th·ª±c hi·ªán c√°c ph√©p t√≠nh to√°n h·ªçc',
                        'action': 'ƒêang t√≠nh to√°n'
                    },
                    'PythonREPL': {
                        'name': 'Python REPL',
                        'purpose': 'Ch·∫°y code Python ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu ph·ª©c t·∫°p',
                        'action': 'ƒêang ch·∫°y code'
                    }
                }
                
                tool_info = tool_descriptions.get(action_name, {
                    'name': action_name,
                    'purpose': f'S·ª≠ d·ª•ng c√¥ng c·ª• {action_name}',
                    'action': 'ƒêang x·ª≠ l√Ω'
                })
                
                # Emit tool executing event
                if self.websocket_callback:
                    await self.websocket_callback({
                        'type': 'reasoning',
                        'step': start_step + iteration,
                        'status': 'executing',
                        'description': tool_info['action'],
                        'tool_name': tool_info['name'],
                        'tool_purpose': tool_info['purpose'],
                        'thought': thought,
                        'action': action_name,
                        'action_input': action_input[:300]
                    })
                
                # Execute tool FIRST, then emit completed (kh√¥ng emit executing ri√™ng)
                if action_name in self.tool_map:
                    tool = self.tool_map[action_name]
                    logger.info(f"[ReAct Agent] Executing tool: {action_name}")
                    
                    try:
                        import inspect
                        if inspect.iscoroutinefunction(tool.func):
                            observation = await tool.func(action_input)
                        else:
                            observation = tool.func(action_input)
                        tools_used.add(action_name)
                        
                        # Emit CH·ªà 1 event completed (sau khi tool xong)
                        if self.websocket_callback:
                            obs_str = str(observation).strip()
                            result_preview = obs_str[:200]
                            
                            # Ph√¢n lo·∫°i k·∫øt qu·∫£ chi ti·∫øt
                            if not obs_str or len(obs_str) < 10:
                                status_msg = "‚ùå Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p"
                                result_quality = "empty"
                            elif "kh√¥ng t√¨m th·∫•y" in obs_str.lower() or "no results" in obs_str.lower():
                                status_msg = "‚ö†Ô∏è T√¨m ki·∫øm kh√¥ng c√≥ k·∫øt qu·∫£"
                                result_quality = "not_found"
                            elif len(obs_str) > 100:
                                status_msg = f"‚úÖ T√¨m th·∫•y {len(obs_str)} k√Ω t·ª± th√¥ng tin"
                                result_quality = "good"
                            else:
                                status_msg = "‚úÖ C√≥ k·∫øt qu·∫£"
                                result_quality = "partial"
                            
                            await self.websocket_callback({
                                'type': 'reasoning',
                                'step': start_step + iteration,
                                'status': 'completed',
                                'description': status_msg,
                                'result_quality': result_quality,
                                'thought': thought,
                                'action': action_name,
                                'action_input': action_input[:300],
                                'observation': obs_str[:500],
                                'result_preview': result_preview,
                                'result_length': len(obs_str)
                            })
                            
                            await self.websocket_callback({
                                'type': 'tool_completed',
                                'tool_name': tool_info['name'],
                                'tool': action_name,
                                'status': status_msg,
                                'result_quality': result_quality,
                                'result_preview': result_preview,
                                'step': iteration + 1
                            })
                        
                        reasoning_steps.append({
                            'tool': action_name,
                            'input': action_input,
                            'output': str(observation)[:500]
                        })
                        
                        messages.append(AIMessage(content=response_text))
                        messages.append(HumanMessage(content=f"Observation: {observation}"))
                        
                    except Exception as e:
                        logger.error(f"[ReAct Agent] Tool execution error: {e}")
                        
                        # Emit reasoning step FAILED
                        if self.websocket_callback:
                            await self.websocket_callback({
                                'type': 'reasoning',
                                'step': start_step + iteration,
                                'status': 'failed',
                                'description': f"L·ªói: {str(e)[:100]}",
                                'thought': thought,
                                'action': action_name,
                                'action_input': action_input[:200],
                                'error': str(e)
                            })
                        
                        messages.append(AIMessage(content=response_text))
                        messages.append(HumanMessage(content=f"Observation: L·ªói khi th·ª±c thi tool: {str(e)}"))
                else:
                    logger.warning(f"[ReAct Agent] Unknown tool: {action_name}")
                    
                    # Emit reasoning step FAILED
                    if self.websocket_callback:
                        await self.websocket_callback({
                            'type': 'reasoning',
                            'step': start_step + iteration,
                            'status': 'failed',
                            'description': f"C√¥ng c·ª• '{action_name}' kh√¥ng t·ªìn t·∫°i",
                            'thought': thought,
                            'action': action_name,
                            'action_input': action_input[:200]
                        })
                    
                    messages.append(AIMessage(content=response_text))
                    messages.append(HumanMessage(content=f"Observation: C√¥ng c·ª• '{action_name}' kh√¥ng t·ªìn t·∫°i. C√°c c√¥ng c·ª• kh·∫£ d·ª•ng: {list(self.tool_map.keys())}"))
            
            logger.warning("[ReAct Agent] Max iterations reached")
            return {
                'answer': "Xin l·ªói, t√¥i c·∫ßn nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ n√†y. B·∫°n c√≥ th·ªÉ th·ª≠ ƒë∆°n gi·∫£n h√≥a c√¢u h·ªèi kh√¥ng?",
                'reasoning_steps': reasoning_steps,
                'tools_used': list(tools_used),
                'success': False
            }
            
        except Exception as e:
            logger.error(f"[ReAct Agent] Error: {e}", exc_info=True)
            return {
                'answer': f"Xin l·ªói, ƒë√£ c√≥ l·ªói khi x·ª≠ l√Ω: {str(e)}",
                'reasoning_steps': [],
                'tools_used': [],
                'success': False,
                'error': str(e)
            }


# ============================================================================
# PART 3: LEARNING AGENT (HIGH-LEVEL ORCHESTRATOR)
# ============================================================================

class LearningAgent:
    """AI Agent for learning mode - Orchestrates ReAct agent and handles conversation"""
    
    def __init__(self, db: Session, user_id: int, websocket_callback=None):
        self.db = db
        self.user_id = user_id
        self.websocket_callback = websocket_callback
        self.llm_provider = get_llm_provider()
        self.conversation_history = []
        self.structure_id = self._get_active_structure_id()
    
    def _get_active_structure_id(self) -> Optional[int]:
        """Get the currently active teaching structure"""
        structure = self.db.query(models.CustomTeachingStructure).filter(
            models.CustomTeachingStructure.is_active == True
        ).first()
        return structure.id if structure else None
    
    async def process_query(self, user_query: str, conversation_context: List[Dict[str, str]] = None) -> Dict:
        """Process a learning query - main entry point"""
        
        intent = await self._classify_intent(user_query)
        logger.info(f"[Learning Agent] Intent classified: {intent}")
        
        if intent['type'] == 'casual_chat':
            response = await self._generate_casual_response(user_query, conversation_context)
            return {
                'response': response,
                'context_used': '',
                'needs_clarification': False
            }
        
        elif intent['type'] == 'greeting':
            return {
                'response': 'Xin ch√†o! T√¥i l√† tr·ª£ l√Ω h·ªçc t·∫≠p c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ h·ªèi t√¥i v·ªÅ b·∫•t k·ª≥ n·ªôi dung n√†o trong t√†i li·ªáu ƒë√£ t·∫£i l√™n, ho·∫∑c g·ª≠i b√†i t·∫≠p c·∫ßn gi·∫£i. T√¥i lu√¥n s·∫µn s√†ng h·ªó tr·ª£ b·∫°n! üòä',
                'context_used': '',
                'needs_clarification': False
            }
        
        elif intent['type'] in ['study_question', 'problem_solving']:
            needs_tools = intent.get('needs_tools', False)
            
            if needs_tools or intent['type'] == 'problem_solving':
                logger.info(f"[Learning Agent] Using ReAct agent")
                result = await solve_with_react_agent(
                    db=self.db,
                    user_id=self.user_id,
                    query=user_query,
                    conversation_history=conversation_context,
                    structure_id=self.structure_id,
                    websocket_callback=self.websocket_callback
                )
                
                if result['success']:
                    return {
                        'response': result['answer'],
                        'context_used': '',
                        'needs_clarification': False,
                        'reasoning_steps': result.get('reasoning_steps', [])
                    }
            
            # Fallback to general response
            response = await self._generate_general_response(user_query, conversation_context)
            return {
                'response': response,
                'context_used': '',
                'needs_clarification': False
            }
        
        else:
            response = await self._generate_general_response(user_query, conversation_context)
            return {
                'response': response,
                'context_used': '',
                'needs_clarification': False
            }
    
    async def _classify_intent(self, user_query: str) -> Dict:
        """Use LLM to classify user intent"""
        classification_prompt = f"""Ph√¢n t√≠ch c√¢u h·ªèi/tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√† x√°c ƒë·ªãnh √Ω ƒë·ªãnh.

C√¢u h·ªèi: "{user_query}"

H√£y ph√¢n lo·∫°i v√†o M·ªòT trong c√°c lo·∫°i sau:
1. greeting - L·ªùi ch√†o h·ªèi
2. casual_chat - Tr√≤ chuy·ªán th√¥ng th∆∞·ªùng
3. study_question - C√¢u h·ªèi v·ªÅ ki·∫øn th·ª©c
4. problem_solving - B√†i t·∫≠p c·∫ßn gi·∫£i

ƒê√°nh gi√°:
- needs_tools: C√≥ c·∫ßn c√¥ng c·ª• t√≠nh to√°n/search kh√¥ng? (true/false)

Tr·∫£ l·ªùi b·∫±ng JSON: {{"type": "lo·∫°i", "needs_tools": true/false}}"""

        try:
            messages = [{"role": "user", "content": classification_prompt}]
            response = await self.llm_provider.chat(
                messages=messages, 
                temperature=0.1
            )
            
            if response:
                content = self._extract_text_from_llm(response)
                try:
                    json_start = content.find('{')
                    json_end = content.rfind('}') + 1
                    if json_start >= 0 and json_end > json_start:
                        json_str = content[json_start:json_end]
                        intent = json.loads(json_str)
                        return intent
                except:
                    pass
            
            return self._fallback_intent_classification(user_query)
            
        except Exception as e:
            logger.error(f"Error in intent classification: {e}")
            return self._fallback_intent_classification(user_query)
    
    def _fallback_intent_classification(self, query: str) -> Dict:
        """Fallback heuristic classification"""
        query_lower = query.lower().strip()
        
        greeting_words = ['xin ch√†o', 'ch√†o', 'hello', 'hi', 'hey']
        if any(word in query_lower for word in greeting_words) and len(query_lower.split()) <= 5:
            return {'type': 'greeting', 'needs_tools': False}
        
        casual_patterns = ['b·∫°n l√† ai', 'b·∫°n t√™n g√¨', 'c·∫£m ∆°n']
        if any(pattern in query_lower for pattern in casual_patterns):
            return {'type': 'casual_chat', 'needs_tools': False}
        
        study_words = ['gi·∫£i', 'b√†i t·∫≠p', 't√≠nh', 't√¨m', 'ch·ª©ng minh']
        if any(word in query_lower for word in study_words):
            return {'type': 'problem_solving', 'needs_tools': True}
        
        return {'type': 'study_question', 'needs_tools': True}
    
    async def _generate_casual_response(self, query: str, conversation_context: Optional[List[Dict[str, str]]] = None) -> str:
        """Generate natural response for casual chat"""
        system_prompt = """B·∫°n l√† tr·ª£ l√Ω h·ªçc t·∫≠p th√¢n thi·ªán. Tr·∫£ l·ªùi ng·∫Øn g·ªçn (2-3 c√¢u)."""
        
        try:
            messages = [{"role": "system", "content": system_prompt}]
            if conversation_context:
                messages.extend(conversation_context[-4:])
            messages.append({"role": "user", "content": query})
            
            response = await self.llm_provider.chat(
                messages=messages, 
                temperature=0.7
            )
            
            if response:
                return self._extract_text_from_llm(response)
            
            return "T√¥i hi·ªÉu r·ªìi! B·∫°n c√≥ c√¢u h·ªèi g√¨ v·ªÅ h·ªçc t·∫≠p kh√¥ng?"
            
        except Exception as e:
            logger.error(f"Error generating casual response: {e}")
            return "T√¥i ·ªü ƒë√¢y ƒë·ªÉ gi√∫p b·∫°n h·ªçc t·∫≠p. B·∫°n c√≥ c√¢u h·ªèi g√¨ kh√¥ng?"
    
    async def _generate_general_response(self, query: str, conversation_context: Optional[List[Dict[str, str]]] = None) -> str:
        """Generate response for general knowledge questions"""
        system_prompt = """B·∫°n l√† tr·ª£ l√Ω h·ªçc t·∫≠p. Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n ki·∫øn th·ª©c chung.

FORMAT C√îNG TH·ª®C TO√ÅN H·ªåC:
- C√¥ng th·ª©c inline: $...$ (VD: $x^2 + y^2 = z^2$)
- C√¥ng th·ª©c block: $$...$$ (VD: $$\\int_a^b f(x) dx$$)
- Ph√¢n s·ªë: $\\frac{a}{b}$, CƒÉn: $\\sqrt{x}$, L≈©y th·ª´a: $x^n$
- LU√îN wrap c√¥ng th·ª©c trong $ ho·∫∑c $$"""
        
        try:
            messages = [{"role": "system", "content": system_prompt}]
            if conversation_context:
                messages.extend(conversation_context[-4:])
            messages.append({"role": "user", "content": query})
            
            response = await self.llm_provider.chat(
                messages=messages, 
                temperature=0.5
            )
            
            if response:
                return self._extract_text_from_llm(response)
            
            return "T√¥i c·∫ßn th√™m th√¥ng tin ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y ch√≠nh x√°c h∆°n."
            
        except Exception as e:
            logger.error(f"Error generating general response: {e}")
            return "Xin l·ªói, t√¥i g·∫∑p kh√≥ khƒÉn khi x·ª≠ l√Ω c√¢u h·ªèi n√†y."
    
    def _extract_text_from_llm(self, response: dict) -> str:
        """Extract text content from LLM response"""
        # Gemini format
        candidates = response.get("candidates")
        if isinstance(candidates, list) and candidates:
            cand0 = candidates[0]
            if isinstance(cand0, dict):
                content = cand0.get("content")
                if isinstance(content, dict):
                    parts = content.get("parts")
                    if isinstance(parts, list) and parts:
                        text = parts[0].get("text")
                        if text:
                            return text.strip()
        
        # OpenAI format
        choices = response.get("choices")
        if isinstance(choices, list) and choices:
            msg = choices[0].get("message")
            if isinstance(msg, dict):
                content = msg.get("content")
                if content:
                    return content.strip()
        
        # Fallback
        if isinstance(response, str):
            return response.strip()
        
        return str(response)


# ============================================================================
# PART 4: PUBLIC API
# ============================================================================

async def generate_learning_response(
    db: Session,
    user_id: int,
    user_query: str,
    conversation_history: List[Dict[str, str]] = None,
    websocket_callback=None
) -> Dict:
    """
    Main entry point for generating learning mode responses
    
    Args:
        db: Database session
        user_id: User ID
        user_query: User's question
        conversation_history: Previous conversation context
        websocket_callback: Optional callback for streaming
    
    Returns:
        Dictionary with response and metadata
    """
    agent = LearningAgent(db, user_id, websocket_callback)
    result = await agent.process_query(user_query, conversation_history)
    return result


async def solve_with_react_agent(
    db,
    user_id: int,
    query: str,
    conversation_history: Optional[List[Dict]] = None,
    structure_id: Optional[int] = None,
    websocket_callback=None
) -> Dict[str, Any]:
    """Convenience function to create and use ReAct agent"""
    agent = ReActLearningAgent(db, user_id, structure_id, websocket_callback)
    result = await agent.solve(query, conversation_history)
    return result
