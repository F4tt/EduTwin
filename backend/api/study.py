from datetime import datetime
from typing import Dict, List
from collections import defaultdict
import json
import logging
import re
import traceback

from fastapi import APIRouter, Depends, HTTPException, Request
from fastapi.responses import JSONResponse
from pydantic import BaseModel, field_validator
from sqlalchemy.orm import Session

logger = logging.getLogger("uvicorn.error")

from db import models, database
from core.study_constants import (
    SUBJECTS,
    SUBJECT_DISPLAY,
    GRADE_ORDER,
    SEMESTER_ORDER,
    GRADE_DISPLAY,
    SEMESTER_DISPLAY,
)
from ml import prediction_service
# REMOVED: learning_documents and vector_store_provider imports (no longer used)
from services.chatbot_service import generate_chat_response
from services.ml_version_manager import ensure_user_predictions_updated
from utils.session_utils import require_auth, get_current_user
from core.websocket_manager import emit_study_update, emit_prediction_update

router = APIRouter(prefix="/study", tags=["Study"])


def build_structure() -> Dict[str, Dict[str, List[str]]]:
    structure: Dict[str, Dict[str, List[str]]] = {}
    for grade in GRADE_ORDER:
        structure[grade] = {}
        for semester in SEMESTER_ORDER[grade]:
            structure[grade][semester] = SUBJECTS.copy()
    return structure


STUDY_STRUCTURE = build_structure()

TERM_ORDER = [
    "1_10",
    "2_10",
    "1_11",
    "2_11",
    "1_12",
    "2_12",
]
TERM_INDEX = {token: idx for idx, token in enumerate(TERM_ORDER)}

KHOI_TN_SUBJECTS = {
    "Toan",
    "Ngu van",
    "Tieng Anh",
    "Vat ly",
    "Hoa hoc",
    "Sinh hoc",
}

KHOI_XH_SUBJECTS = {
    "Toan",
    "Ngu van",
    "Tieng Anh",
    "Lich su",
    "Dia ly",
    "Giao duc cong dan",
}

EXAM_BLOCKS = {
    "A00": ["Toan", "Vat ly", "Hoa hoc"],
    "B00": ["Toan", "Hoa hoc", "Sinh hoc"],
    "C00": ["Ngu van", "Lich su", "Dia ly"],
    "D01": ["Toan", "Ngu van", "Tieng Anh"],
}


def normalize_term_token(token: str | None) -> str | None:
    if not token:
        return None
    parts = str(token).split("_")
    if len(parts) != 2:
        return None
    semester = parts[0].upper()
    grade = parts[1]
    return f"{semester}_{grade}"


def term_index_for_token(token: str | None) -> int | None:
    normalized = normalize_term_token(token)
    if not normalized:
        return None
    return TERM_INDEX.get(normalized)


def validate_combination(grade_level: str, semester: str, subject: str) -> None:
    if grade_level not in STUDY_STRUCTURE:
        raise HTTPException(status_code=400, detail="Khá»‘i lá»›p khÃ´ng há»£p lá»‡")
    if semester not in STUDY_STRUCTURE[grade_level]:
        raise HTTPException(status_code=400, detail="Há»c ká»³ khÃ´ng há»£p lá»‡")
    if subject not in STUDY_STRUCTURE[grade_level][semester]:
        raise HTTPException(status_code=400, detail="MÃ´n há»c khÃ´ng há»£p lá»‡")


class ScoreRecord(BaseModel):
    subject: str
    grade_level: str
    semester: str
    score: float

    @field_validator("grade_level")
    @classmethod
    def normalize_grade(cls, v: str) -> str:
        grade = str(v).upper()
        return grade

    @field_validator("semester")
    @classmethod
    def normalize_semester(cls, v: str) -> str:
        return str(v).upper()

    @field_validator("subject")
    @classmethod
    def normalize_subject(cls, v: str) -> str:
        return v.strip()

    @field_validator("score")
    @classmethod
    def validate_score(cls, v: float) -> float:
        if v < 0 or v > 10:
            raise ValueError("Äiá»ƒm pháº£i náº±m trong khoáº£ng 0-10")
        return v


class ScoreBulkPayload(BaseModel):
    scores: List[ScoreRecord]


class ScoreDeleteRecord(BaseModel):
    subject: str
    grade_level: str
    semester: str


class ScoreDeletePayload(BaseModel):
    scores: List[ScoreDeleteRecord]


class GenerateCommentsRequest(BaseModel):
    active_tab: str | None = None  # Tab Ä‘ang xem: "Chung", "Khá»‘i TN", "Khá»‘i XH", "Tá»• Há»£p", "Tá»«ng MÃ´n"
    persist: bool = False  # CÃ³ lÆ°u vÃ o database khÃ´ng (cho cross-device sync)


def get_db():
    db = database.SessionLocal()
    try:
        yield db
    finally:
        db.close()


# REMOVED: /embeddings/rebuild endpoint (vector store no longer used)


def build_scores_payload(db: Session, user_id: int) -> Dict[str, object]:
    user = db.query(models.User).filter(models.User.id == user_id).first()
    rows = (
        db.query(models.StudyScore)
        .filter(models.StudyScore.user_id == user_id)
        .all()
    )
    row_map = {
        (row.subject, row.grade_level, row.semester): row
        for row in rows
    }

    scores_output: List[Dict[str, object]] = []
    actual_count = 0
    term_value_map = defaultdict(list)

    for grade in GRADE_ORDER:
        for semester in SEMESTER_ORDER[grade]:
            for subject in STUDY_STRUCTURE[grade][semester]:
                key = f"{subject}_{semester}_{grade}"
                row = row_map.get((subject, grade, semester))
                actual = row.actual_score if row else None
                predicted = row.predicted_score if row else None
                if actual is not None:
                    actual_count += 1

                visible_value = actual if actual is not None else predicted
                if visible_value is not None:
                    term_key = f"{semester}_{grade}"
                    term_value_map[term_key].append(float(visible_value))

                scores_output.append(
                    {
                        "key": key,
                        "subject": subject,
                        "subject_display": SUBJECT_DISPLAY.get(subject, subject),
                        "grade_level": grade,
                        "semester": semester,
                        "actual": actual,
                        "predicted": predicted,
                        "actual_source": row.actual_source if row else None,
                        "predicted_source": row.predicted_source if row else None,
                    }
                )

    term_averages = []
    for grade in GRADE_ORDER:
        for semester in SEMESTER_ORDER[grade]:
            term_key = f"{semester}_{grade}"
            values = term_value_map.get(term_key, [])
            average = round(sum(values) / len(values), 2) if values else None
            term_averages.append(
                {
                    "term": term_key,
                    "label": term_key,
                    "average": average,
                    "count": len(values),
                }
            )

    return {
        "scores": scores_output,
        "actual_count": actual_count,
        "term_averages": term_averages,
        "current_grade": getattr(user, "current_grade", None) if user else None,
        "grade_display": GRADE_DISPLAY,
        "semester_display": SEMESTER_DISPLAY,
        "subject_display": SUBJECT_DISPLAY,
        "prediction_threshold_min": 5,
        "prediction_threshold_max": 30,
    }


@router.get("/scores")
@require_auth
def get_scores(request: Request, db: Session = Depends(get_db)):
    user_session = get_current_user(request)
    if not user_session:
        raise HTTPException(status_code=401, detail="ChÆ°a Ä‘Äƒng nháº­p")

    user_id = user_session.get("user_id")
    
    # Ensure user has latest predictions (lazy evaluation)
    ensure_user_predictions_updated(db, user_id)
    
    return build_scores_payload(db, user_id)


@router.post("/scores/delete")
@require_auth
def delete_scores(request: Request, payload: ScoreDeletePayload, db: Session = Depends(get_db)):
    """Clear actual score fields for the given user-owned score records."""
    user_session = get_current_user(request)
    if not user_session:
        raise HTTPException(status_code=401, detail="ChÆ°a Ä‘Äƒng nháº­p")

    user_id = user_session.get("user_id")
    deleted = 0
    deleted_rows: List[models.StudyScore] = []
    for record in payload.scores:
        try:
            validate_combination(record.grade_level, record.semester, record.subject)
        except HTTPException:
            continue

        score_entry = (
            db.query(models.StudyScore)
            .filter(
                models.StudyScore.user_id == user_id,
                models.StudyScore.grade_level == record.grade_level,
                models.StudyScore.semester == record.semester,
                models.StudyScore.subject == record.subject,
            )
            .first()
        )

        if score_entry and score_entry.actual_score is not None:
            score_entry.actual_score = None
            score_entry.actual_source = None
            score_entry.actual_status = None
            score_entry.actual_updated_at = None
            deleted += 1
            deleted_rows.append(score_entry)

    if deleted_rows:
        # REMOVED: Vector store sync (not needed for score analytics)
        # vector_store = get_vector_store()
        try:
            db.flush()
            # recompute predictions after clearing scores
            predicted_scores = prediction_service.update_predictions_for_user(db, user_id)
            # REMOVED: learning_documents.sync_score_embeddings(db, vector_store, deleted_rows + predicted_scores)
            db.commit()
        except Exception:
            db.rollback()
            raise

    return {"deleted": deleted}


@router.post("/scores/bulk")
@require_auth
def upsert_scores(request: Request, payload: ScoreBulkPayload, db: Session = Depends(get_db)):
    """Create or update multiple score records for the authenticated user."""
    user_session = get_current_user(request)
    if not user_session:
        raise HTTPException(status_code=401, detail="ChÆ°a Ä‘Äƒng nháº­p")

    user_id = user_session.get("user_id")
    if not payload.scores:
        raise HTTPException(status_code=400, detail="Danh sÃ¡ch Ä‘iá»ƒm trá»‘ng")

    updated_rows: List[models.StudyScore] = []
    validation_errors: List[str] = []

    for idx, record in enumerate(payload.scores, start=1):
        try:
            validate_combination(record.grade_level, record.semester, record.subject)
        except HTTPException as exc:
            validation_errors.append(f"Báº£n ghi {idx}: {exc.detail}")
            continue

        row = (
            db.query(models.StudyScore)
            .filter(
                models.StudyScore.user_id == user_id,
                models.StudyScore.grade_level == record.grade_level,
                models.StudyScore.semester == record.semester,
                models.StudyScore.subject == record.subject,
            )
            .first()
        )
        if not row:
            row = models.StudyScore(
                user_id=user_id,
                subject=record.subject,
                grade_level=record.grade_level,
                semester=record.semester,
            )
            db.add(row)

        row.actual_score = round(float(record.score), 2)
        row.actual_source = "user_portal"
        row.actual_status = "confirmed"
        row.actual_updated_at = datetime.utcnow()
        updated_rows.append(row)

    if validation_errors and not updated_rows:
        raise HTTPException(status_code=400, detail="; ".join(validation_errors))

    prediction_updates: List[models.StudyScore] = []
    try:
        db.flush()
        logger.info(f"[BULK] Starting ML pipeline for user {user_id}, updated {len(updated_rows)} actual scores")
        prediction_updates = prediction_service.update_predictions_for_user(db, user_id) or []
        logger.info(f"[BULK] ML pipeline returned {len(prediction_updates)} prediction updates")
        
        # Flush again to assign IDs to prediction_updates
        db.flush()
        
        # REMOVED: Vector store sync (not needed for score analytics)
        # if updated_rows or prediction_updates:
        #     vector_store = get_vector_store()
        #     learning_documents.sync_score_embeddings(db, vector_store, updated_rows + prediction_updates)
        
        db.commit()
        logger.info(f"[BULK] Successfully committed changes for user {user_id}")
        
        # Emit realtime update via WebSocket
        try:
            import asyncio
            asyncio.create_task(emit_study_update(user_id, {
                'type': 'score_update',
                'updated_count': len(updated_rows),
                'prediction_count': len(prediction_updates),
                'timestamp': datetime.utcnow().isoformat()
            }))
            asyncio.create_task(emit_prediction_update(user_id, {
                'predictions': [
                    {
                        'subject': p.subject,
                        'grade_level': p.grade_level,
                        'semester': p.semester,
                        'score': p.predicted_score
                    } for p in prediction_updates
                ],
                'timestamp': datetime.utcnow().isoformat()
            }))
        except Exception as ws_err:
            logger.warning(f"Failed to emit WebSocket updates: {ws_err}")
            
    except HTTPException:
        db.rollback()
        raise
    except Exception as exc:
        db.rollback()
        logger.exception("Failed to upsert study scores", exc_info=exc)
        detail = validation_errors[0] if validation_errors else "KhÃ´ng thá»ƒ lÆ°u Ä‘iá»ƒm há»c táº­p"
        raise HTTPException(status_code=500, detail=detail)

    snapshot = build_scores_payload(db, user_id)
    logger.info(f"[BULK] Built snapshot with {len(snapshot.get('scores', []))} score records for user {user_id}")

    response = {
        "updated": len(updated_rows),
        "prediction_updates": len(prediction_updates),
        "scores_snapshot": snapshot,
    }
    if validation_errors:
        response["warnings"] = validation_errors
    return response


def subject_label(subject: str) -> str:
    return SUBJECT_DISPLAY.get(subject, subject)


def format_score(value: float | None) -> str:
    if value is None:
        return "-"
    return f"{value:.2f}".rstrip("0").rstrip(".")


def format_term_label(term: str) -> str:
    try:
        semester, grade = term.split("_")
    except ValueError:
        return term
    sem_label = SEMESTER_DISPLAY.get(semester, f"Há»c ká»³ {semester}")
    grade_label = GRADE_DISPLAY.get(grade, f"Lá»›p {grade}")
    return f"{sem_label} {grade_label}"


def collect_visible_entries(
    score_rows: List[models.StudyScore],
    current_idx: int | None,
) -> List[Dict[str, object]]:
    entries: List[Dict[str, object]] = []
    fallback_index = len(TERM_ORDER)
    for row in score_rows:
            
        source = "actual" if row.actual_score is not None else "predicted"
        value = row.actual_score if row.actual_score is not None else row.predicted_score
        if value is None:
            continue
        term_token = f"{row.semester}_{row.grade_level}"
        term_idx = TERM_INDEX.get(term_token, fallback_index)
        is_future = False
        if current_idx is not None:
            is_future = term_idx > current_idx
        else:
            is_future = source == "predicted"

        entries.append(
            {
                "subject": row.subject,
                "term": term_token,
                "term_index": term_idx,
                "value": float(value),
                "source": source,
                "is_future": is_future,
            }
        )
    return entries


def compute_term_series(entries: List[Dict[str, object]], subject_filter: set[str] | None = None) -> List[tuple[str, float]]:
    term_buckets: Dict[str, List[float]] = defaultdict(list)
    for entry in entries:
        if subject_filter and entry["subject"] not in subject_filter:
            continue
        term_buckets[entry["term"]].append(entry["value"])

    series: List[tuple[str, float]] = []
    for term in TERM_ORDER:
        values = term_buckets.get(term)
        if values:
            avg = round(sum(values) / len(values), 2)
            series.append((term, avg))

    # include any extra terms that may appear (e.g., TN) ordered by index then name
    extra_terms = [term for term in term_buckets if term not in TERM_INDEX]
    for term in sorted(extra_terms):
        values = term_buckets[term]
        avg = round(sum(values) / len(values), 2)
        series.append((term, avg))

    return series


def compute_subject_stats(entries: List[Dict[str, object]], subject_filter: set[str] | None = None, current_idx: int | None = None) -> Dict[str, Dict[str, float]]:
    subject_entries: Dict[str, List[Dict[str, object]]] = defaultdict(list)
    for entry in entries:
        if subject_filter and entry["subject"] not in subject_filter:
            continue
        subject_entries[entry["subject"]].append(entry)

    stats: Dict[str, Dict[str, float]] = {}
    for subject, seq in subject_entries.items():
        ordered = sorted(seq, key=lambda item: item["term_index"])
        
        # Filter to only include entries up to and including current_idx
        if current_idx is not None:
            ordered = [item for item in ordered if item["term_index"] <= current_idx]
        
        values = [item["value"] for item in ordered]
        if not values:
            continue
        avg = round(sum(values) / len(values), 2)
        trend = round(ordered[-1]["value"] - ordered[0]["value"], 2) if len(ordered) >= 2 else 0.0
        stats[subject] = {
            "average": avg,
            "latest_value": round(ordered[-1]["value"], 2),
            "latest_term": ordered[-1]["term"],
            "trend": trend,
            "max_value": round(max(values), 2),
            "min_value": round(min(values), 2),
        }
    return stats


def join_with_and(items: List[str]) -> str:
    if not items:
        return ""
    if len(items) == 1:
        return items[0]
    return ", ".join(items[:-1]) + f" vÃ  {items[-1]}"


def describe_summary(avg_score: float | None, subject_stats: Dict[str, Dict[str, float]]) -> str:
    if avg_score is None or not subject_stats:
        return "ChÆ°a cÃ³ Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ tá»•ng káº¿t chung."
    total_subjects = len(subject_stats)
    sorted_subjects = sorted(subject_stats.items(), key=lambda item: item[1]["average"], reverse=True)
    top_segments = [f"{subject_label(sub)} ({format_score(stats['average'])})" for sub, stats in sorted_subjects[:2]]
    weak_segments = [f"{subject_label(sub)} ({format_score(stats['average'])})" for sub, stats in sorted_subjects[-1:]]
    sentences = [
        f"Äiá»ƒm trung bÃ¬nh tá»•ng thá»ƒ Ä‘ang á»Ÿ má»©c {format_score(avg_score)} trÃªn {total_subjects} mÃ´n cÃ³ dá»¯ liá»‡u.",
    ]
    if top_segments:
        sentences.append(f"Tháº¿ máº¡nh ná»•i báº­t náº±m á»Ÿ {join_with_and(top_segments)}.")
    if weak_segments:
        sentences.append(f"MÃ´n cáº§n chÃº Ã½ nháº¥t lÃ  {join_with_and(weak_segments)}.")
    return " ".join(sentences)


def describe_trend(term_series: List[tuple[str, float]], context_label: str) -> str:
    if not term_series:
        return f"ChÆ°a cÃ³ dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch xu hÆ°á»›ng cá»§a {context_label.lower()}."
    start_term, start_value = term_series[0]
    end_term, end_value = term_series[-1]
    delta = round(end_value - start_value, 2)
    if delta > 0.3:
        movement = "tÄƒng Ä‘á»u"
    elif delta < -0.3:
        movement = "giáº£m nháº¹"
    else:
        movement = "giá»¯ á»•n Ä‘á»‹nh"
    trend_sentence = (
        f"Xu hÆ°á»›ng {movement} tá»« {format_term_label(start_term)} ({format_score(start_value)}) "
        f"Ä‘áº¿n {format_term_label(end_term)} ({format_score(end_value)}), chÃªnh lá»‡ch {format_score(abs(delta))} Ä‘iá»ƒm."
    )
    peak_term, peak_value = max(term_series, key=lambda item: item[1])
    if peak_term != end_term:
        trend_sentence += f" Cá»™t má»‘c cao nháº¥t thuá»™c {format_term_label(peak_term)} vá»›i {format_score(peak_value)} Ä‘iá»ƒm."
    return trend_sentence


def describe_subject_ranking(subject_stats: Dict[str, Dict[str, float]], context_label: str) -> str:
    if not subject_stats:
        return f"ChÆ°a cÃ³ dá»¯ liá»‡u so sÃ¡nh mÃ´n há»c cá»§a {context_label.lower()}."
    ordered = sorted(subject_stats.items(), key=lambda item: item[1]["average"], reverse=True)
    top = ordered[:2]
    bottom = ordered[-2:]
    top_text = join_with_and([f"{subject_label(sub)} ({format_score(stats['average'])})" for sub, stats in top])
    bottom_text = join_with_and([f"{subject_label(sub)} ({format_score(stats['average'])})" for sub, stats in bottom])
    gap = None
    if top and bottom:
        gap = round(top[0][1]["average"] - bottom[-1][1]["average"], 2)
    comparison = f"NhÃ³m dáº«n Ä‘áº§u gá»“m {top_text}."
    if bottom_text:
        comparison += f" NhÃ³m cáº§n cáº£i thiá»‡n lÃ  {bottom_text}."
    if gap is not None and gap > 0:
        comparison += f" Khoáº£ng cÃ¡ch giá»¯a máº¡nh nháº¥t vÃ  yáº¿u nháº¥t Ä‘ang á»Ÿ má»©c {format_score(gap)} Ä‘iá»ƒm."
    return comparison


def describe_radar(subject_stats: Dict[str, Dict[str, float]], context_label: str) -> str:
    if not subject_stats:
        return f"Radar chÆ°a cÃ³ dá»¯ liá»‡u cho {context_label.lower()}."
    ordered = sorted(subject_stats.items(), key=lambda item: item[1]["average"], reverse=True)
    strengths = ordered[:2]
    gaps = ordered[-2:]
    strength_text = join_with_and([subject_label(sub) for sub, _ in strengths])
    gap_text = join_with_and([subject_label(sub) for sub, _ in gaps])
    strength_avg = sum(stats["average"] for _, stats in strengths) / len(strengths) if strengths else 0
    gap_avg = sum(stats["average"] for _, stats in gaps) / len(gaps) if gaps else 0
    delta = round(strength_avg - gap_avg, 2)
    sentence = f"Radar cho tháº¥y {strength_text} Ä‘ang lÃ  tháº¿ máº¡nh trung bÃ¬nh {format_score(strength_avg)}."
    if gap_text:
        sentence += f" {gap_text} tháº¥p hÆ¡n khoáº£ng {format_score(delta)} Ä‘iá»ƒm nÃªn cáº§n Ä‘Æ°á»£c bá»• sung thÃªm thá»i gian." 
    return sentence


def summarize_examples(
    entries: List[Dict[str, object]],
    subject_filter: set[str] | None,
    current_idx: int | None,
    limit: int = 4,
) -> tuple[List[str], List[str]]:
    filtered = [entry for entry in entries if (not subject_filter or entry["subject"] in subject_filter)]
    ordered = sorted(filtered, key=lambda item: item["term_index"])
    actual_examples: List[str] = []
    future_examples: List[str] = []
    for entry in ordered:
        label = (
            f"{subject_label(entry['subject'])} - {format_term_label(entry['term'])}: "
            f"{format_score(entry['value'])} Ä‘iá»ƒm"
        )
        descriptor = " (thá»±c táº¿)"
        bucket = actual_examples
        if entry.get("is_future"):
            descriptor = " (dá»± Ä‘oÃ¡n)"
            bucket = future_examples
        elif entry.get("source") == "predicted" and current_idx is None:
            descriptor = " (dá»± Ä‘oÃ¡n)"
            bucket = future_examples
        bucket.append(label + descriptor)
    return actual_examples[:limit], future_examples[:limit]


def extract_json_dict(text: str) -> Dict[str, object]:
    """Extract JSON from LLM response, handling various formats."""
    if not text:
        return {}
    text = text.strip()
    
    # Try direct JSON parse first
    try:
        parsed = json.loads(text)
        if isinstance(parsed, dict):
            return parsed
    except Exception:
        pass

    # Remove markdown code blocks (```json ... ``` or ``` ... ```)
    if "```" in text:
        # Extract content between ```json and ``` or ``` and ```
        import re
        match = re.search(r"```(?:json)?\s*(\{[\s\S]*?\})\s*```", text)
        if match:
            try:
                parsed = json.loads(match.group(1))
                if isinstance(parsed, dict):
                    return parsed
            except Exception:
                pass

    # Find JSON object in text
    match = re.search(r"\{[\s\S]*\}", text)
    if match:
        try:
            parsed = json.loads(match.group(0))
            if isinstance(parsed, dict):
                return parsed
        except Exception:
            pass
    
    return {}


def build_chart_data_for_llm(
    entries: List[Dict[str, object]],
    subject_filter: set[str] | None,
    current_idx: int | None,
    current_grade_token: str | None,
) -> Dict[str, object]:
    """
    Build RAW chart data that is ACTUALLY DISPLAYED on UI charts.
    This ensures LLM only analyzes data visible to users.
    """
    filtered_entries = [entry for entry in entries if (not subject_filter or entry["subject"] in subject_filter)]
    
    # Filter to current_idx for most charts
    if current_idx is not None:
        current_entries = [e for e in filtered_entries if e["term_index"] <= current_idx]
    else:
        current_entries = filtered_entries
    
    # 1. LineChart data: Term averages (past + future)
    term_buckets: Dict[str, List[float]] = defaultdict(list)
    for entry in filtered_entries:
        term_buckets[entry["term"]].append(entry["value"])
    
    linechart_data = []
    for term in TERM_ORDER:
        values = term_buckets.get(term)
        if values:
            avg = round(sum(values) / len(values), 2)
            term_idx = TERM_INDEX.get(term, 999)
            is_past = current_idx is None or term_idx <= current_idx
            linechart_data.append({
                "term": format_term_label(term),
                "average": avg,
                "type": "past" if is_past else "future"
            })
    
    # 2. BarChart data: Subject averages (up to current only)
    subject_buckets: Dict[str, List[float]] = defaultdict(list)
    for entry in current_entries:
        subject_buckets[entry["subject"]].append(entry["value"])
    
    barchart_data = []
    for subject in SUBJECTS:
        values = subject_buckets.get(subject)
        if values:
            avg = round(sum(values) / len(values), 2)
            barchart_data.append({
                "subject": subject_label(subject),
                "average": avg
            })
    # Sort by average descending
    barchart_data.sort(key=lambda x: x["average"], reverse=True)
    
    # 3. RadarChart data: Current term only
    radar_data = []
    if current_grade_token:
        parts = current_grade_token.split('_')
        if len(parts) == 2:
            semester, grade = parts
            for entry in filtered_entries:
                if entry["term"] == current_grade_token:
                    radar_data.append({
                        "subject": subject_label(entry["subject"]),
                        "score": entry["value"]
                    })
    
    return {
        "linechart": linechart_data,
        "barchart": barchart_data,
        "radar": radar_data,
        "current_term": format_term_label(current_grade_token) if current_grade_token else "ChÆ°a xÃ¡c Ä‘á»‹nh",
    }


def build_context_comment(
    entries: List[Dict[str, object]],
    subject_filter: set[str] | None,
    include_summary: bool,
    context_label: str,
    current_idx: int | None,
    current_grade_label: str,
) -> Dict[str, object]:
    filtered_entries = [entry for entry in entries if (not subject_filter or entry["subject"] in subject_filter)]
    
    # Filter to only include entries up to and including current_idx
    if current_idx is not None:
        filtered_entries = [entry for entry in filtered_entries if entry["term_index"] <= current_idx]
    
    values = [entry["value"] for entry in filtered_entries]
    avg_score = round(sum(values) / len(values), 2) if values else None
    subject_stats = compute_subject_stats(entries, subject_filter, current_idx)
    term_series = compute_term_series(entries, subject_filter)
    actual_examples, future_examples = summarize_examples(entries, subject_filter, current_idx)

    return {
        "summary": describe_summary(avg_score, subject_stats) if include_summary else None,
        "trend": describe_trend(term_series, context_label),
        "subjects": describe_subject_ranking(subject_stats, context_label),
        "radar": describe_radar(subject_stats, context_label),
        "actual_examples": actual_examples,
        "future_examples": future_examples,
        "context_label": context_label,
        "current_grade_label": current_grade_label,
    }


def classify_block_fit(avg_score: float) -> str:
    if avg_score >= 8.5:
        return "ráº¥t phÃ¹ há»£p"
    if avg_score >= 7.5:
        return "khÃ¡ phÃ¹ há»£p"
    if avg_score >= 6.5:
        return "cáº§n cÃ¢n nháº¯c"
    return "chÆ°a phÃ¹ há»£p"


def build_exam_block_insights(
    entries: List[Dict[str, object]],
    current_idx: int | None,
    current_grade_label: str,
) -> Dict[str, object]:
    block_details: Dict[str, Dict[str, object]] = {}
    ranking: List[tuple[str, float]] = []

    for block, subjects in EXAM_BLOCKS.items():
        subject_filter = set(subjects)
        subject_stats = compute_subject_stats(entries, subject_filter, current_idx)
        if not subject_stats:
            block_details[block] = {
                "comment": "ChÆ°a cÃ³ dá»¯ liá»‡u Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ khá»‘i nÃ y.",
                "average": None,
                "actual_examples": [],
                "future_examples": [],
                "context_label": f"Khá»‘i {block}",
                "current_grade_label": current_grade_label,
            }
            continue
        subject_avgs = [stats["average"] for stats in subject_stats.values()]
        block_avg = round(sum(subject_avgs) / len(subject_avgs), 2)
        ranking.append((block, block_avg))
        ordered = sorted(subject_stats.items(), key=lambda item: item[1]["average"], reverse=True)
        best = ordered[0]
        weakest = ordered[-1]
        fit_label = classify_block_fit(block_avg)
        comment = (
            f"Khá»‘i {block} Ä‘áº¡t trung bÃ¬nh {format_score(block_avg)}, ná»•i báº­t á»Ÿ {subject_label(best[0])} ({format_score(best[1]['average'])}). "
            f"{subject_label(weakest[0])} ({format_score(weakest[1]['average'])}) lÃ  Ä‘iá»ƒm cáº§n cá»§ng cá»‘ Ä‘á»ƒ {fit_label} hÆ¡n."
        )
        actual_examples, future_examples = summarize_examples(entries, subject_filter, current_idx)
        block_details[block] = {
            "comment": comment,
            "average": block_avg,
            "best_subject": subject_label(best[0]),
            "weak_subject": subject_label(weakest[0]),
            "actual_examples": actual_examples,
            "future_examples": future_examples,
            "context_label": f"Khá»‘i {block}",
            "current_grade_label": current_grade_label,
        }

    ranking = sorted([item for item in ranking if item[1] is not None], key=lambda item: item[1], reverse=True)
    if not ranking:
        headline = "ChÆ°a Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ gá»£i Ã½ khá»‘i thi phÃ¹ há»£p."
    else:
        best_block, best_avg = ranking[0]
        runner = ranking[1] if len(ranking) > 1 else None
        fit_label = classify_block_fit(best_avg)
        best_detail = block_details.get(best_block, {})
        reason = best_detail.get("best_subject") or "cÃ¡c mÃ´n tháº¿ máº¡nh"
        headline = f"NÃªn Æ°u tiÃªn khá»‘i {best_block} ({format_score(best_avg)}) vÃ¬ {reason} Ä‘ang thá»ƒ hiá»‡n {fit_label}."
        if runner and runner[1] is not None:
            gap = round(best_avg - runner[1], 2)
            headline += f" Khá»‘i {runner[0]} Ä‘á»©ng sau vá»›i má»©c {format_score(runner[1])}, chÃªnh {format_score(gap)} Ä‘iá»ƒm."

    return {
        "headline": headline,
        "blocks": block_details,
    }


def build_subject_comments(
    entries: List[Dict[str, object]],
    current_idx: int | None,
    current_grade_label: str,
    current_grade_token: str | None,
) -> Dict[str, Dict[str, object]]:
    subject_stats = compute_subject_stats(entries, None, current_idx)
    comments: Dict[str, Dict[str, object]] = {}
    for subject in SUBJECTS:
        stats = subject_stats.get(subject)
        if not stats:
            comments[subject] = {
                "comment": "ChÆ°a cÃ³ dá»¯ liá»‡u.",
                "average": None,
                "chart_data": {"linechart": []},
                "actual_examples": [],
                "future_examples": [],
                "context_label": subject_label(subject),
                "current_grade_label": current_grade_label,
            }
            continue
        
        # Build chart data for this subject (LineChart showing term progression)
        subject_entries = [e for e in entries if e["subject"] == subject]
        term_buckets: Dict[str, List[float]] = defaultdict(list)
        for entry in subject_entries:
            term_buckets[entry["term"]].append(entry["value"])
        
        linechart_data = []
        for term in TERM_ORDER:
            values = term_buckets.get(term)
            if values:
                avg = round(sum(values) / len(values), 2)
                term_idx = TERM_INDEX.get(term, 999)
                is_past = current_idx is None or term_idx <= current_idx
                linechart_data.append({
                    "term": format_term_label(term),
                    "average": avg,
                    "type": "past" if is_past else "future"
                })
        
        chart_data = {"linechart": linechart_data}
        
        trend = stats["trend"]
        if trend > 0.3:
            trend_text = "Ä‘ang cáº£i thiá»‡n"
        elif trend < -0.3:
            trend_text = "giáº£m nháº¹"
        else:
            trend_text = "duy trÃ¬ á»•n Ä‘á»‹nh"
        latest_label = format_term_label(stats["latest_term"])
        comment = (
            f"{subject_label(subject)} giá»¯ trung bÃ¬nh {format_score(stats['average'])} vÃ  {trend_text} tá»›i {latest_label}."
        )
        actual_examples, future_examples = summarize_examples(entries, {subject}, current_idx)
        comments[subject] = {
            "comment": comment,
            "average": stats["average"],
            "chart_data": chart_data,
            "actual_examples": actual_examples,
            "future_examples": future_examples,
            "context_label": subject_label(subject),
            "current_grade_label": current_grade_label,
        }
    return comments


@router.post("/generate-slide-comments")
@require_auth
async def generate_slide_comments(
    request: Request,
    payload: GenerateCommentsRequest,
    db: Session = Depends(get_db)
):
    """Build deterministic study insights for each DataViz section.
    
    Now supports targeted analysis for specific tabs to reduce processing time and token usage.
    """
    current_user = get_current_user(request)
    if not current_user:
        raise HTTPException(status_code=401, detail="ChÆ°a Ä‘Äƒng nháº­p")

    # Get active tab from request
    active_tab = payload.active_tab or "Chung"
    
    user_id = current_user.get("user_id")
    user = db.query(models.User).filter(models.User.id == user_id).first()
    current_grade_token = getattr(user, "current_grade", None) if user else None
    normalized_grade = normalize_term_token(current_grade_token)
    current_idx = term_index_for_token(current_grade_token)
    current_grade_label = format_term_label(normalized_grade) if normalized_grade else "ChÆ°a thiáº¿t láº­p"

    scores = (
        db.query(models.StudyScore)
        .filter(models.StudyScore.user_id == user_id)
        .all()
    )

    if not scores:
        raise HTTPException(status_code=400, detail="ChÆ°a cÃ³ dá»¯ liá»‡u Ä‘iá»ƒm Ä‘á»ƒ sinh nháº­n xÃ©t")

    actual_count = sum(1 for s in scores if s.actual_score is not None)
    entries = collect_visible_entries(scores, current_idx)

    if not entries:
        raise HTTPException(status_code=400, detail="ChÆ°a cÃ³ Ä‘iá»ƒm thá»±c táº¿ hoáº·c dá»± Ä‘oÃ¡n Ä‘á»ƒ sinh nháº­n xÃ©t")

    # Build RAW CHART DATA for each tab (data actually displayed on UI)
    overview_chart_data = {
        "Chung": build_chart_data_for_llm(entries, None, current_idx, current_grade_token),
        "Khá»‘i TN": build_chart_data_for_llm(entries, KHOI_TN_SUBJECTS, current_idx, current_grade_token),
        "Khá»‘i XH": build_chart_data_for_llm(entries, KHOI_XH_SUBJECTS, current_idx, current_grade_token),
    }

    exam_block_comments = build_exam_block_insights(entries, current_idx, current_grade_label)
    subject_comments = build_subject_comments(entries, current_idx, current_grade_label, current_grade_token)
    block_details = exam_block_comments.get("blocks", {})

    # Build exam block chart data (for tá»• há»£p tab)
    exam_blocks_chart_data = []
    for block, subjects in EXAM_BLOCKS.items():
        block_entries = [e for e in entries if e["subject"] in subjects]
        
        # Calculate TOTAL scores for LineChart (not averages)
        term_subject_scores: Dict[str, Dict[str, float]] = defaultdict(dict)
        for entry in block_entries:
            term_subject_scores[entry["term"]][entry["subject"]] = entry["value"]
        
        linechart_data = []
        for term in TERM_ORDER:
            subject_scores = term_subject_scores.get(term, {})
            # Only include if we have all 3 subjects
            if len(subject_scores) == 3:
                total = round(sum(subject_scores.values()), 2)
                term_idx = TERM_INDEX.get(term, 999)
                is_past = current_idx is None or term_idx <= current_idx
                linechart_data.append({
                    "term": format_term_label(term),
                    "total": total,
                    "type": "past" if is_past else "future"
                })
        
        # BarChart: individual subject averages (up to current)
        block_data = build_chart_data_for_llm(entries, set(subjects), current_idx, current_grade_token)
        
        exam_blocks_chart_data.append({
            "id": block,
            "subjects": [subject_label(s) for s in subjects],
            "linechart": linechart_data,
            "barchart": block_data["barchart"],
        })

    # Prepare overview payload with RAW CHART DATA
    overview_payload = [
        {
            "id": tab_name,
            "chart_data": chart_data,
        }
        for tab_name, chart_data in overview_chart_data.items()
    ]

    exam_blocks_payload = {
        "blocks": exam_blocks_chart_data,
    }

    subject_payload = [
        {
            "id": subject,
            "display": details.get("context_label"),
            "average": details.get("average"),
            "chart_data": details.get("chart_data"),
            "comment": details.get("comment"),
            "actual_examples": details.get("actual_examples"),
            "future_examples": details.get("future_examples"),
            "current_grade_label": details.get("current_grade_label"),
        }
        for subject, details in subject_comments.items()
    ]

    shared_meta = {
        "user_id": user_id,
        "current_grade_label": current_grade_label,
        "current_grade_token": current_grade_token,
        "actual_scores_count": actual_count,
    }

    async def ask_llm_for_group(title: str, instructions: List[str], data_payload: object, schema_hint: object) -> Dict[str, object]:
        """Enhanced LLM request with educational knowledge context."""
        from services.educational_knowledge import get_educational_context
        from services.dataset_analyzer import get_dataset_insights_for_llm
        
        # Add educational knowledge and dataset insights
        edu_context = get_educational_context()
        dataset_insights = get_dataset_insights_for_llm(db, current_user.get("user_id"))
        
        payload_json = json.dumps(data_payload, ensure_ascii=False, indent=2)
        schema_json = json.dumps(schema_hint, ensure_ascii=False, indent=2)
        
        context_header = [
            f"== {title} ==",
            "",
            "# ğŸ“š KIáº¾N THá»¨C Ná»€N Vá»€ Há»† THá»NG GIÃO Dá»¤C:",
            edu_context[:2500],  # Increased - more context for deeper analysis
            ""
        ]
        
        if dataset_insights:
            context_header.extend([
                "",
                "# ğŸ“Š Dá»® LIá»†U THAM KHáº¢O & Máº¶T Báº°NG CHUNG:",
                "Báº®T BUá»˜C: Sá»¬ Dá»¤NG sá»‘ liá»‡u nÃ y Ä‘á»ƒ so sÃ¡nh vá»‹ trÃ­ há»c sinh",
                dataset_insights[:2000],  # Increased - critical for benchmarking
                ""
            ])
        
        prompt = "\n".join(
            context_header
            + instructions
            + ["", "# Dá»® LIá»†U Cáº¦N PHÃ‚N TÃCH:", payload_json, "", 
               "# YÃŠU Cáº¦U Äá»ŠNH Dáº NG:", 
               "Báº®T BUá»˜C: Tráº£ vá» ÄÃšNG JSON format nhÆ° sau (KHÃ”NG thÃªm text nÃ o khÃ¡c):", 
               schema_json,
               "",
               "CHÃš Ã: Chá»‰ tráº£ vá» JSON object, KHÃ”NG markdown, KHÃ”NG giáº£i thÃ­ch thÃªm."]
        )
        try:
            logger.info(f"[AI_ANALYSIS] Calling LLM for: {title}")
            outcome = await generate_chat_response(
                db=db,
                user=current_user,
                message=prompt,
                session_id="__silent__",
            )
            answer = (outcome.get("answer") or "").strip()
            logger.info(f"[AI_ANALYSIS] Got response for {title}, length: {len(answer)}")
            if not answer:
                logger.warning(f"[AI_ANALYSIS] Empty response for {title}")
            else:
                # Log first 500 chars of response for debugging
                logger.info(f"[AI_ANALYSIS] Response preview: {answer[:500]}")
        except Exception as e:
            logger.error(f"[AI_ANALYSIS] Error calling LLM for {title}: {e}")
            answer = ""
        result = extract_json_dict(answer)
        logger.info(f"[AI_ANALYSIS] Extracted JSON for {title}: {list(result.keys()) if result else 'empty'}")
        return result

    # Alias for single chart analysis
    ask_llm_for_chart = ask_llm_for_group
    
    def build_summary_instructions() -> List[str]:
        """Instructions for SUMMARY analysis - focuses on current position vs benchmark."""
        return [
            "Báº¡n lÃ  trá»£ lÃ½ há»c táº­p AI cá»§a EduTwin.",
            "XÆ°ng hÃ´: mÃ¬nh-báº¡n (mÃ¬nh lÃ  AI, báº¡n lÃ  há»c sinh).",
            "",
            "# NHIá»†M Vá»¤: Viáº¿t SUMMARY (Tá»•ng quan 4-5 cÃ¢u)",
            "",
            "# Dá»® LIá»†U NHáº¬N ÄÆ¯á»¢C:",
            "- linechart: Äiá»ƒm TB qua cÃ¡c há»c ká»³",
            "- current_term: Há»c ká»³ hiá»‡n táº¡i",
            "- Benchmark tá»« 'Dá»® LIá»†U THAM KHáº¢O': median, p75, p90",
            "",
            "# Cáº¤U TRÃšC (4-5 cÃ¢u):",
            "",
            "CÃ‚U 1: Vá»Š TRÃ HIá»†N Táº I + SO SÃNH BENCHMARK",
            "  - Láº¥y Ä‘iá»ƒm TB há»c ká»³ hiá»‡n táº¡i: linechart â†’ pháº§n tá»­ CUá»I cÃ³ type='past' â†’ field 'average'",
            "  - So sÃ¡nh vá»›i benchmark: median, p75, p90",
            "  - ÄÃ¡nh giÃ¡: Top bao nhiÃªu %? Má»©c Ä‘á»™ nÃ o (Xuáº¥t sáº¯c/Giá»i/KhÃ¡/TB)?",
            "  VD: 'á» HK1/12, PhÃ¡t ThÃ nh Ä‘áº¡t 7.89 Ä‘iá»ƒm (KhÃ¡), náº±m giá»¯a median (7.44) vÃ  p75 (8.5),",
            "       cao hÆ¡n 50% há»c sinh nhÆ°ng cáº§n +0.61 Ä‘iá»ƒm Ä‘á»ƒ vÃ o Top 25%.'",
            "",
            "CÃ‚U 2-3: PHÃ‚N TÃCH NGUYÃŠN NHÃ‚N",
            "  - Khoáº£ng cÃ¡ch giá»¯a cao nháº¥t - tháº¥p nháº¥t?",
            "  - Ã nghÄ©a: NÄƒng khiáº¿u? Máº¥t cÃ¢n báº±ng?",
            "",
            "CÃ‚U 4-5: Háº¬U QUáº¢ & HÃ€NH Äá»˜NG",
            "  - CÆ¡ há»™i Ä‘á»— Ä‘áº¡i há»c vá»›i vá»‹ trÃ­ nÃ y?",
            "  - Cáº§n cáº£i thiá»‡n bao nhiÃªu Ä‘á»ƒ Ä‘áº¡t má»¥c tiÃªu?",
            "  - Gá»£i Ã½ chiáº¿n lÆ°á»£c cá»¥ thá»ƒ",
            "",
            "QUAN TRá»ŒNG:",
            "- PHáº¢I láº¥y Ä‘iá»ƒm tá»« linechart, KHÃ”NG tá»± tÃ­nh",
            "- PHáº¢I so sÃ¡nh vá»›i benchmark tá»« Dá»® LIá»†U THAM KHáº¢O",
            "- NÃªu rÃµ nguá»“n: 'LineChart cho tháº¥y...', 'Theo benchmark...'",
            "",
            "Tráº£ vá» JSON: {\"summary\": \"...\"}"
        ]
    
    def build_trend_instructions() -> List[str]:
        """Instructions for TREND analysis - focuses on changes over time."""
        return [
            "Báº¡n lÃ  trá»£ lÃ½ há»c táº­p AI cá»§a EduTwin.",
            "XÆ°ng hÃ´: mÃ¬nh-báº¡n (mÃ¬nh lÃ  AI, báº¡n lÃ  há»c sinh).",
            "",
            "# NHIá»†M Vá»¤: Viáº¿t TREND (Xu hÆ°á»›ng 4-5 cÃ¢u)",
            "",
            "# Dá»® LIá»†U NHáº¬N ÄÆ¯á»¢C:",
            "- linechart: Äiá»ƒm TB qua cÃ¡c há»c ká»³ (HK1/10 â†’ HK2/10 â†’ HK1/11 â†’ ...)",
            "- Má»—i pháº§n tá»­ cÃ³: term, average, type (past/future)",
            "",
            "# Cáº¤U TRÃšC (4-5 cÃ¢u):",
            "",
            "CÃ‚U 1: MÃ” Táº¢ XU HÆ¯á»šNG Tá»”NG THá»‚",
            "  - TÄƒng/Giáº£m/Dao Ä‘á»™ng/á»”n Ä‘á»‹nh? Tá»‘c Ä‘á»™?",
            "  - Sá»‘ liá»‡u cá»¥ thá»ƒ: HK1/10 (X) â†’ HK2/10 (Y) â†’ HK1/11 (Z)",
            "  VD: 'LineChart cho tháº¥y xu hÆ°á»›ng TÄ‚NG á»•n Ä‘á»‹nh tá»« 7.2 (HK1/10) lÃªn 7.89 (HK1/12),",
            "       tá»‘c Ä‘á»™ trung bÃ¬nh +0.15 Ä‘iá»ƒm/ká»³.'",
            "",
            "CÃ‚U 2-3: PHÃ‚N TÃCH Báº¤T THÆ¯á»œNG & NGUYÃŠN NHÃ‚N",
            "  - Há»c ká»³ nÃ o cÃ³ biáº¿n Ä‘á»™ng Lá»šN (tÄƒng/giáº£m >0.3)?",
            "  - Táº I SAO? NguyÃªn nhÃ¢n cÃ³ thá»ƒ?",
            "  - So vá»›i xu hÆ°á»›ng chung - BÃ¬nh thÆ°á»ng hay báº¥t thÆ°á»ng?",
            "  VD: 'Äáº·c biá»‡t, HK1/11 giáº£m 0.5 Ä‘iá»ƒm - Báº¤T THÆ¯á»œNG vÃ¬ Ä‘Ã¢y lÃ  giai Ä‘oáº¡n cÆ¡ báº£n.",
            "       CÃ³ thá»ƒ do thay Ä‘á»•i phÆ°Æ¡ng phÃ¡p há»c hoáº·c tÃ¢m lÃ½.'",
            "",
            "CÃ‚U 4-5: Dá»° ÄOÃN & HÃ€NH Äá»˜NG",
            "  - Náº¿u cÃ³ type='future': ÄÃ¡nh giÃ¡ tÃ­nh kháº£ thi",
            "  - Náº¿u duy trÃ¬ xu hÆ°á»›ng, káº¿t quáº£ ra sao?",
            "  - Cáº§n lÃ m gÃ¬ Ä‘á»ƒ cáº£i thiá»‡n/duy trÃ¬?",
            "",
            "QUAN TRá»ŒNG:",
            "- CHá»ˆ phÃ¢n tÃ­ch dá»¯ liá»‡u trong linechart",
            "- PhÃ¢n biá»‡t rÃµ past (thá»±c táº¿) vÃ  future (dá»± Ä‘oÃ¡n)",
            "- TÃ¬m QUY LUáº¬T, khÃ´ng chá»‰ mÃ´ táº£",
            "",
            "Tráº£ vá» JSON: {\"trend\": \"...\"}"
        ]
    
    def build_bars_instructions() -> List[str]:
        """Instructions for SUBJECTS analysis - focuses on comparing subjects."""
        return [
            "Báº¡n lÃ  trá»£ lÃ½ há»c táº­p AI cá»§a EduTwin.",
            "XÆ°ng hÃ´: mÃ¬nh-báº¡n (mÃ¬nh lÃ  AI, báº¡n lÃ  há»c sinh).",
            "",
            "# NHIá»†M Vá»¤: Viáº¿t SUBJECTS (So sÃ¡nh mÃ´n 4-5 cÃ¢u)",
            "",
            "# Dá»® LIá»†U NHáº¬N ÄÆ¯á»¢C:",
            "- barchart: Äiá»ƒm TB tá»«ng mÃ´n (cho Ä‘áº¿n hiá»‡n táº¡i)",
            "- Má»—i pháº§n tá»­ cÃ³: subject (tÃªn mÃ´n), average (Ä‘iá»ƒm TB)",
            "",
            "# Cáº¤U TRÃšC (4-5 cÃ¢u):",
            "",
            "CÃ‚U 1-2: PHÃ‚N LOáº I NHÃ“M MÃ”N",
            "  - NhÃ³m Máº NH: CÃ¡c mÃ´n cao nháº¥t?",
            "  - NhÃ³m Yáº¾U: CÃ¡c mÃ´n tháº¥p nháº¥t?",
            "  - Äá»™ chÃªnh lá»‡ch giá»¯a cÃ¡c nhÃ³m?",
            "  VD: 'BarChart cho tháº¥y Sá»° PHÃ‚N TÃCH: Khá»‘i TN táº¡o \"táº§ng cao\" (ToÃ¡n 8.9, LÃ½ 8.7, HÃ³a 8.5),",
            "       trong khi khá»‘i XH á»Ÿ \"táº§ng tháº¥p\" (Sá»­ 7.1, Äá»‹a 6.9, GDCD 6.5). ChÃªnh lá»‡ch 1.8-2.4 Ä‘iá»ƒm.'",
            "",
            "CÃ‚U 3-4: Ã NGHÄ¨A & Gá»¢I Ã",
            "  - Tá»• há»£p nÃ o PHÃ™ Há»¢P nháº¥t?",
            "  - MÃ´n nÃ o cáº§n cáº£i thiá»‡n? Cáº§n tÄƒng bao nhiÃªu?",
            "  - Chiáº¿n lÆ°á»£c tá»‘i Æ°u?",
            "  VD: 'ÄÃ¢y lÃ  TÃN HIá»†U rÃµ vá» nÄƒng khiáº¿u TN - khÃ´ng pháº£i Ä‘iá»ƒm yáº¿u XH!",
            "       Thay vÃ¬ cÃ¢n báº±ng (sai láº§m), hÃ£y táº­p trung A00/B00. Äáº©y 3 mÃ´n TN lÃªn 9.0+",
            "       â†’ 27+ Ä‘iá»ƒm tá»•ng â†’ Ä‘á»§ thi ÄHBK, ÄHQG.'",
            "",
            "QUAN TRá»ŒNG:",
            "- CHá»ˆ phÃ¢n tÃ­ch dá»¯ liá»‡u trong barchart",
            "- TÃ¬m NHÃ“M, QUY LUáº¬T, khÃ´ng chá»‰ liá»‡t kÃª",
            "- LiÃªn há»‡ vá»›i Tá»” Há»¢P thi Ä‘áº¡i há»c",
            "",
            "Tráº£ vá» JSON: {\"subjects\": \"...\"}"
        ]
    
    def build_radar_instructions() -> List[str]:
        """Instructions for RADAR analysis - focuses on current term distribution."""
        return [
            "Báº¡n lÃ  trá»£ lÃ½ há»c táº­p AI cá»§a EduTwin.",
            "XÆ°ng hÃ´: mÃ¬nh-báº¡n (mÃ¬nh lÃ  AI, báº¡n lÃ  há»c sinh).",
            "",
            "# NHIá»†M Vá»¤: Viáº¿t RADAR (PhÃ¢n bá»• Ä‘iá»ƒm 4-5 cÃ¢u)",
            "",
            "# Dá»® LIá»†U NHáº¬N ÄÆ¯á»¢C:",
            "- radar: Äiá»ƒm tá»«ng mÃ´n trong Há»ŒC Ká»² HIá»†N Táº I",
            "- current_term: Há»c ká»³ Ä‘ang phÃ¢n tÃ­ch",
            "- Má»—i pháº§n tá»­ cÃ³: subject (tÃªn mÃ´n), score (Ä‘iá»ƒm)",
            "",
            "# Cáº¤U TRÃšC (4-5 cÃ¢u):",
            "",
            "CÃ‚U 1: MÃ” Táº¢ HÃŒNH Dáº NG RADAR",
            "  - CÃ¢n Ä‘á»‘i (trÃ²n Ä‘á»u) hay máº¥t cÃ¢n báº±ng (gÃ³c nhá»n)?",
            "  - Äá»™ chÃªnh cao-tháº¥p?",
            "  VD: 'Radar HK1/12 cho tháº¥y HÃŒNH Dáº NG Máº¤T CÃ‚N Báº°NG vá»›i Ä‘á»™ chÃªnh 2.4 Ä‘iá»ƒm.'",
            "",
            "CÃ‚U 2: PHÃ‚N TÃCH Cá»¤M/NHÃ“M",
            "  - MÃ´n nÃ o táº¡o cá»¥m Äá»ˆNH cao?",
            "  - MÃ´n nÃ o táº¡o cá»¥m ÄÃY tháº¥p?",
            "  - CÃ³ quy luáº­t? (TN cao hÆ¡n XH? TÃ­nh toÃ¡n cao hÆ¡n ghi nhá»›?)",
            "  VD: '3 mÃ´n TN (ToÃ¡n 8.9, LÃ½ 8.7, HÃ³a 8.5) táº¡o \"cá»¥m Ä‘á»‰nh\" á»Ÿ gÃ³c pháº£i,",
            "       trong khi 3 mÃ´n XH (Sá»­ 7.1, Äá»‹a 6.9, GDCD 6.5) táº¡o \"cá»¥m Ä‘Ã¡y\" á»Ÿ gÃ³c trÃ¡i.'",
            "",
            "CÃ‚U 3-4: TÆ¯Æ NG QUAN & NGUYÃŠN NHÃ‚N",
            "  - Táº¡i sao cÃ¡c mÃ´n nÃ y cÃ¹ng cao/tháº¥p?",
            "  - LiÃªn quan NÄ‚NG KHIáº¾U? PhÆ°Æ¡ng phÃ¡p há»c? Sá»Ÿ thÃ­ch?",
            "  - Nháº¥t quÃ¡n vá»›i xu hÆ°á»›ng tá»« LineChart khÃ´ng?",
            "",
            "CÃ‚U 5: Káº¾T LUáº¬N & CHIáº¾N LÆ¯á»¢C",
            "  - Radar nÃ y cho tháº¥y gÃ¬ vá» Báº¢N THÃ‚N há»c sinh?",
            "  - NÃªn PHÃT HUY gÃ¬? KHáº®C PHá»¤C gÃ¬?",
            "  - Chiáº¿n lÆ°á»£c tá»‘i Æ°u cho tÆ°Æ¡ng lai?",
            "  VD: 'Radar kháº³ng Ä‘á»‹nh nÄƒng khiáº¿u TN rÃµ rÃ ng. Thay vÃ¬ cá»‘ cÃ¢n báº±ng táº¥t cáº£,",
            "       hÃ£y Äáº¨Y Máº NH 3 mÃ´n TN lÃªn 9.0+ trong 2 thÃ¡ng tá»›i Ä‘á»ƒ tá»‘i Æ°u A00/B00.'",
            "",
            "QUAN TRá»ŒNG:",
            "- CHá»ˆ phÃ¢n tÃ­ch dá»¯ liá»‡u trong radar (há»c ká»³ hiá»‡n táº¡i)",
            "- TÃ¬m INSIGHT, TÆ¯Æ NG QUAN, khÃ´ng chá»‰ mÃ´ táº£",
            "- Giáº£i thÃ­ch NGUYÃŠN NHÃ‚N, Háº¬U QUáº¢, GIÃ TRá»Š",
            "",
            "Tráº£ vá» JSON: {\"radar\": \"...\"}"
        ]

    def build_exam_blocks_instructions() -> List[str]:
        """Instructions for EXAM BLOCKS tab - analyzing combined subject blocks for university entrance."""
        return [
            "Báº¡n lÃ  trá»£ lÃ½ há»c táº­p AI cá»§a EduTwin.",
            "XÆ°ng hÃ´: mÃ¬nh-báº¡n (mÃ¬nh lÃ  AI, báº¡n lÃ  há»c sinh).",
            "",
            "# NHIá»†M Vá»¤: PhÃ¢n tÃ­ch TOÃ€N DIá»†N tá»«ng KHá»I THI Äáº I Há»ŒC",
            "",
            "# Dá»® LIá»†U NHáº¬N ÄÆ¯á»¢C:",
            "- meta: current_grade_label (há»c ká»³ hiá»‡n táº¡i), actual_scores_count",
            "- blocks: Danh sÃ¡ch cÃ¡c khá»‘i (A00, B00, C00, D01)",
            "- Má»—i block cÃ³:",
            "  * subjects: 3 mÃ´n trong khá»‘i",
            "  * linechart: [{term, total, type='past'/'future'}] - Tá»”NG ÄIá»‚M 3 mÃ´n qua cÃ¡c ká»³",
            "  * barchart: [{subject, average}] - Äiá»ƒm TB tá»«ng mÃ´n (Ä‘áº¿n hiá»‡n táº¡i)",
            "- Dá»® LIá»†U THAM KHáº¢O (benchmark): median, p75, p90 cá»§a khá»‘i thi",
            "- KIáº¾N THá»¨C: Äiá»ƒm chuáº©n cÃ¡c trÆ°á»ng, yÃªu cáº§u thi Ä‘áº¡i há»c",
            "",
            "# Cáº¤U TRÃšC PHÃ‚N TÃCH CHO Má»–I KHá»I (5-8 cÃ¢u):",
            "",
            "## PHáº¦N 1: XU HÆ¯á»šNG & Vá»Š TRÃ HIá»†N Táº I (3-4 cÃ¢u)",
            "Tá»« LINECHART - PhÃ¢n tÃ­ch tá»•ng Ä‘iá»ƒm khá»‘i qua cÃ¡c ká»³:",
            "",
            "CÃ‚U 1: XU HÆ¯á»šNG QUÃ KHá»¨",
            "  - Tá»•ng Ä‘iá»ƒm thay Ä‘á»•i nhÆ° tháº¿ nÃ o tá»« HK1/10 Ä‘áº¿n hiá»‡n táº¡i?",
            "  - á»”n Ä‘á»‹nh/TÄƒng/Giáº£m? Biáº¿n Ä‘á»™ng báº¥t thÆ°á»ng á»Ÿ ká»³ nÃ o?",
            "  VD: 'Khá»‘i A00 cÃ³ xu hÆ°á»›ng tÄƒng á»•n Ä‘á»‹nh tá»« 22.5 (HK1/10) lÃªn 24.8 (HK1/11),",
            "       nhÆ°ng giáº£m xuá»‘ng 23.2 á»Ÿ HK2/11 (báº¥t thÆ°á»ng - cÃ³ thá»ƒ do Ã¡p lá»±c thi cuá»‘i nÄƒm).'",
            "",
            "CÃ‚U 2: Vá»Š TRÃ HIá»†N Táº I + BENCHMARK",
            "  - Láº¥y Ä‘iá»ƒm HIá»†N Táº I: linechart â†’ pháº§n tá»­ CUá»I cÃ³ type='past' â†’ field 'total'",
            "  - So sÃ¡nh vá»›i benchmark: median, p75, p90",
            "  - ÄÃ¡nh giÃ¡: Top bao nhiÃªu %? Äá»§ Ä‘iá»u kiá»‡n trÆ°á»ng nÃ o?",
            "  VD: 'Hiá»‡n táº¡i Ä‘áº¡t 23.2 Ä‘iá»ƒm (HK2/11), cao hÆ¡n median (21.5) nhÆ°ng tháº¥p hÆ¡n p75 (24.0),",
            "       xáº¿p khoáº£ng Top 35-50%. Äiá»ƒm nÃ y CHá»ˆ Äá»¦ vÃ o cÃ¡c trÆ°á»ng khu vá»±c (ÄH ÄÃ  Náºµng ~22),",
            "       CHÆ¯A Äá»¦ cho cÃ¡c trÆ°á»ng top (ÄHBK HÃ  Ná»™i ~25, ÄHQG HCM ~26).'",
            "",
            "CÃ‚U 3-4: NGUYÃŠN NHÃ‚N & ÄÃNH GIÃ",
            "  - Tá»« BARCHART: MÃ´n nÃ o lÃ  CHÃ‚N KIá»€NG? MÃ´n nÃ o KÃ‰O LÃ™I?",
            "  - ChÃªnh lá»‡ch giá»¯a cÃ¡c mÃ´n? Ã nghÄ©a?",
            "  - Tiá»m nÄƒng: Dá»… cáº£i thiá»‡n hay khÃ³?",
            "  VD: 'ToÃ¡n (8.5) vÃ  LÃ½ (8.2) ráº¥t tá»‘t, nhÆ°ng HÃ³a chá»‰ 6.5 - Ä‘Ã¢y lÃ  ÄIá»‚M Yáº¾U kÃ©o tá»•ng xuá»‘ng.",
            "       ChÃªnh 2.0 Ä‘iá»ƒm giá»¯a ToÃ¡n-HÃ³a cho tháº¥y NÄ‚NG Lá»°C khÃ´ng Ä‘á»“ng Ä‘á»u.",
            "       TIN Tá»T: HÃ³a dá»… cáº£i thiá»‡n hÆ¡n ToÃ¡n - náº¿u tÄƒng HÃ³a lÃªn 7.5 â†’ tá»•ng tÄƒng 1.0 Ä‘iá»ƒm!'",
            "",
            "## PHáº¦N 2: Dá»° ÄOÃN TÆ¯Æ NG LAI & CHIáº¾N LÆ¯á»¢C (4-5 cÃ¢u)",
            "Tá»« LINECHART - PhÃ¢n tÃ­ch Ä‘iá»ƒm dá»± Ä‘oÃ¡n:",
            "",
            "CÃ‚U 5: Dá»° ÄOÃN & ÄÃNH GIÃ",
            "  - Náº¿u cÃ³ type='future' trong linechart: Láº¥y Ä‘iá»ƒm dá»± Ä‘oÃ¡n",
            "  - So vá»›i hiá»‡n táº¡i: TÄƒng/Giáº£m? Bao nhiÃªu Ä‘iá»ƒm?",
            "  - Kháº£ thi khÃ´ng? Dá»±a vÃ o xu hÆ°á»›ng quÃ¡ khá»©",
            "  VD: 'Dá»± Ä‘oÃ¡n HK1/12 Ä‘áº¡t 26.0 Ä‘iá»ƒm (+2.8 so vá»›i hiá»‡n táº¡i) - khÃ¡ Láº C QUAN.",
            "       Tuy nhiÃªn, dá»±a vÃ o xu hÆ°á»›ng tÄƒng +0.5 Ä‘iá»ƒm/ká»³ trong quÃ¡ khá»©,",
            "       ká»‹ch báº£n THá»°C Táº¾ hÆ¡n lÃ  24.0-24.5 Ä‘iá»ƒm náº¿u giá»¯ nhá»‹p Ä‘á»™.'",
            "",
            "CÃ‚U 6: CÆ  Há»˜I & KHUYáº¾N NGHá»Š TRÆ¯á»œNG",
            "  - Vá»›i Ä‘iá»ƒm dá»± Ä‘oÃ¡n, Ä‘á»§ Ä‘iá»u kiá»‡n trÆ°á»ng nÃ o?",
            "  - So vá»›i benchmark: VÆ°á»£t p75? p90?",
            "  - Gá»£i Ã½ trÆ°á»ng phÃ¹ há»£p (tá»« KIáº¾N THá»¨C)",
            "  VD: 'Náº¿u Ä‘áº¡t 26.0, vÆ°á»£t p90 (25.5) â†’ Top 10%, Äá»¦ ÄIá»‚M vÃ o ÄHBK HÃ  Ná»™i (~25),",
            "       ÄHQG HCM (~26), tháº­m chÃ­ xÃ©t thá»­ ngÃ nh CÆ¡ khÃ­ ÄHBK (~24.5).",
            "       NhÆ°ng náº¿u chá»‰ Ä‘áº¡t 24.0 â†’ chá»‰ á»Ÿ má»©c p75, Cáº¦N Dá»° PHÃ’NG vá»›i ÄH BÃ¡ch Khoa ÄÃ  Náºµng (~23).'",
            "",
            "CÃ‚U 7: Lá»˜ TRÃŒNH Cáº¢I THIá»†N Cá»¤ THá»‚",
            "  - Tá»« BARCHART: MÃ´n nÃ o cáº§n Æ°u tiÃªn?",
            "  - TÄƒng bao nhiÃªu Ä‘iá»ƒm á»Ÿ mÃ´n nÃ o Ä‘á»ƒ Ä‘áº¡t má»¥c tiÃªu?",
            "  - PhÆ°Æ¡ng phÃ¡p cá»¥ thá»ƒ (tá»« KIáº¾N THá»¨C)",
            "  VD: 'Æ¯U TIÃŠN TUYá»†T Äá»I: HÃ³a há»c (6.5 â†’ 7.5 = +1.0 tá»•ng).",
            "       HÃ nh Ä‘á»™ng: Ã”n láº¡i kiáº¿n thá»©c lá»›p 11 (oxi hÃ³a khá»­, cÃ¢n báº±ng), lÃ m 200 bÃ i táº­p pháº£n á»©ng,",
            "       há»c nhÃ³m vá»›i báº¡n giá»i HÃ³a. KHÃ”NG LÃ€M NHIá»€U ToÃ¡n (Ä‘Ã£ 8.5) - táº­p trung vÃ o Ä‘iá»ƒm yáº¿u!'",
            "",
            "CÃ‚U 8: TÃ‚M LÃ & Äá»˜NG Lá»°C",
            "  - ÄÃ¡nh giÃ¡ TIá»€M NÄ‚NG dá»±a vÃ o quÃ¡ khá»©",
            "  - KhÃ­ch lá»‡ hoáº·c cáº£nh bÃ¡o",
            "  - Lá»i khuyÃªn tinh tháº§n",
            "  VD: 'Xu hÆ°á»›ng quÃ¡ khá»© (+2.3 trong 3 ká»³) chá»©ng tá» báº¡n CÃ“ KHáº¢ NÄ‚NG vÃ  NGHá»Š Lá»°C.",
            "       Äiá»ƒm giáº£m á»Ÿ HK2/11 lÃ  NHáº¤T THá»œI - Ä‘á»«ng náº£n! Náº¿u tiáº¿p tá»¥c phÆ°Æ¡ng phÃ¡p há»c Ä‘Ãºng,",
            "       26.0 Ä‘iá»ƒm HOÃ€N TOÃ€N KHáº¢ THI. HÃ£y tin vÃ o báº£n thÃ¢n!'",
            "",
            "# QUY Táº®C Báº®T BUá»˜C:",
            "- CHá»ˆ dÃ¹ng sá»‘ liá»‡u tá»« linechart (field 'total') vÃ  barchart (field 'average')",
            "- PHáº¢I so sÃ¡nh vá»›i benchmark (median, p75, p90)",
            "- PHáº¢I gá»£i Ã½ trÆ°á»ng cá»¥ thá»ƒ tá»« KIáº¾N THá»¨C",
            "- PHáº¢I phÃ¢n tÃ­ch Cáº¢ quÃ¡ khá»© VÃ€ tÆ°Æ¡ng lai",
            "- NgÃ´n ngá»¯: ThÃ¢n thiá»‡n, Ä‘á»™ng viÃªn, Cá»¤ THá»‚",
            "",
            "# YÃŠU Cáº¦U Tá»”NG QUAN (headline):",
            "Tá»•ng há»£p 2-3 cÃ¢u vá»:",
            "- Khá»‘i nÃ o PHÃ™ Há»¢P NHáº¤T dá»±a vÃ o Ä‘iá»ƒm hiá»‡n táº¡i + xu hÆ°á»›ng?",
            "- Khá»‘i nÃ o cÃ³ TIá»€M NÄ‚NG cao nháº¥t (dá»± Ä‘oÃ¡n tá»‘t)?",
            "- Khuyáº¿n nghá»‹ lá»±a chá»n",
            "",
            "Äá»‹nh dáº¡ng: {\"headline\": \"...\", \"blocks\": [{\"id\": \"A00\", \"comment\": \"...\"}]}",
        ]

    def build_individual_subjects_instructions() -> List[str]:
        """Instructions for INDIVIDUAL SUBJECTS tab - analyzing each subject separately."""
        return [
            "Báº¡n lÃ  trá»£ lÃ½ há»c táº­p AI cá»§a EduTwin.",
            "XÆ°ng hÃ´: mÃ¬nh-báº¡n (mÃ¬nh lÃ  AI, báº¡n lÃ  há»c sinh).",
            "",
            "# NHIá»†M Vá»¤: PhÃ¢n tÃ­ch Tá»ªNG MÃ”N Há»ŒC trong Bá»I Cáº¢NH Tá»”NG THá»‚",
            "",
            "# Dá»® LIá»†U NHáº¬N ÄÆ¯á»¢C:",
            "- subjects: Danh sÃ¡ch 9 mÃ´n (ToÃ¡n, VÄƒn, Anh, LÃ½, HÃ³a, Sinh, Sá»­, Äá»‹a, GDCD)",
            "- Má»—i mÃ´n cÃ³:",
            "  * average: Äiá»ƒm TB tá»•ng (tá»« HK1/10 Ä‘áº¿n hiá»‡n táº¡i)",
            "  * chart_data vá»›i linechart: Xu hÆ°á»›ng Ä‘iá»ƒm qua cÃ¡c ká»³",
            "  * actual_examples: VÃ­ dá»¥ Ä‘iá»ƒm thá»±c táº¿",
            "  * future_examples: VÃ­ dá»¥ Ä‘iá»ƒm dá»± Ä‘oÃ¡n",
            "",
            "# Cáº¤U TRÃšC PHÃ‚N TÃCH CHO Má»–I MÃ”N (4-5 cÃ¢u):",
            "",
            "1. Vá»Š TRÃ SO Vá»šI CÃC MÃ”N KHÃC:",
            "   - Dáº«n Ä‘áº§u/Trung bÃ¬nh/Yáº¿u nháº¥t trong 9 mÃ´n?",
            "   - Äiá»ƒm TB cá»¥ thá»ƒ lÃ  bao nhiÃªu?",
            "",
            "2. XU HÆ¯á»šNG:",
            "   - TÄƒng/Giáº£m/á»”n Ä‘á»‹nh qua cÃ¡c há»c ká»³?",
            "   - Tá»‘c Ä‘á»™ thay Ä‘á»•i?",
            "",
            "3. TIá»€M NÄ‚NG & Dá»° ÄOÃN:",
            "   - Äiá»ƒm dá»± Ä‘oÃ¡n tÆ°Æ¡ng lai (náº¿u cÃ³)?",
            "   - So sÃ¡nh tiá»m nÄƒng vá»›i cÃ¡c mÃ´n khÃ¡c?",
            "",
            "4. KHUYáº¾N NGHá»Š:",
            "   - NÃªn táº­p trung cáº£i thiá»‡n hay duy trÃ¬?",
            "   - Vai trÃ² trong tá»• há»£p thi (A00/B00/C00/D01)?",
            "   - HÃ nh Ä‘á»™ng cá»¥ thá»ƒ?",
            "",
            "# QUY Táº®C:",
            "- So sÃ¡nh vá»›i 8 mÃ´n cÃ²n láº¡i",
            "- DÃ¹ng Sá» LIá»†U cá»¥ thá»ƒ tá»« dá»¯ liá»‡u",
            "- Má»—i mÃ´n 4-5 cÃ¢u, ngáº¯n gá»n",
            "- Gáº¯n vá»›i tá»• há»£p thi Ä‘áº¡i há»c",
            "",
            "# FORMAT RESPONSE - QUAN TRá»ŒNG:",
            "Báº®T BUá»˜C tráº£ vá» JSON object theo format SAU, KHÃ”NG cÃ³ markdown code block, KHÃ”NG cÃ³ text giáº£i thÃ­ch thÃªm:",
            "",
            "{",
            '  "subjects": [',
            '    {"id": "Toan", "comment": "ToÃ¡n Ä‘ang dáº«n Ä‘áº§u vá»›i 8.5 Ä‘iá»ƒm - cao nháº¥t trong 9 mÃ´n. Xu hÆ°á»›ng tÄƒng Ä‘á»u +0.3 Ä‘iá»ƒm/ká»³, á»•n Ä‘á»‹nh hÆ¡n cÃ¡c mÃ´n khÃ¡c. Dá»± Ä‘oÃ¡n HK1/12 Ä‘áº¡t 9.0 - tiá»m nÄƒng cao. LÃ  mÃ´n chung cá»§a 4 tá»• há»£p, nÃªn duy trÃ¬ á»Ÿ má»©c 8.5-9.0 vÃ  táº­p trung cáº£i thiá»‡n mÃ´n yáº¿u hÆ¡n."},',
            '    {"id": "Ngu van", "comment": "..."},',
            '    {"id": "Tieng Anh", "comment": "..."}',
            "  ]",
            "}",
            "",
            "CHá»ˆ TRáº¢ Vá»€ JSON OBJECT, KHÃ”NG THÃŠM Báº¤T Ká»² TEXT NÃ€O KHÃC!",
        ]
   
    

    # ==========================================
    # OPTIMIZED: Only analyze the active tab
    # ==========================================
    
    overview_response = {}
    exam_response = {}
    subject_response = {}
    
    # Determine which analysis to run based on active_tab
    if active_tab in ["Chung", "Khá»‘i TN", "Khá»‘i XH"]:
        # IMPROVED: Separate requests for each chart type to avoid confusion
        selected_tab_data = overview_chart_data.get(active_tab)
        if selected_tab_data:
            # Request 1: SUMMARY - Only linechart (current score) + benchmark
            summary_response = await ask_llm_for_chart(
                f"Tá»•ng quan - {active_tab}",
                build_summary_instructions(),
                {
                    "meta": shared_meta,
                    "tab": active_tab,
                    "linechart": selected_tab_data["linechart"],
                    "current_term": selected_tab_data["current_term"],
                },
                {"summary": ""}
            )
            
            # Request 2: TREND - Only linechart (full timeline)
            trend_response = await ask_llm_for_chart(
                f"Xu hÆ°á»›ng - {active_tab}",
                build_trend_instructions(),
                {
                    "meta": shared_meta,
                    "tab": active_tab,
                    "linechart": selected_tab_data["linechart"],
                },
                {"trend": ""}
            )
            
            # Request 3: SUBJECTS - Only barchart (subject averages)
            subjects_response = await ask_llm_for_chart(
                f"So sÃ¡nh mÃ´n - {active_tab}",
                build_bars_instructions(),
                {
                    "meta": shared_meta,
                    "tab": active_tab,
                    "barchart": selected_tab_data["barchart"],
                },
                {"subjects": ""}
            )
            
            # Request 4: RADAR - Only radar (current term)
            radar_response = await ask_llm_for_chart(
                f"PhÃ¢n bá»• Ä‘iá»ƒm - {active_tab}",
                build_radar_instructions(),
                {
                    "meta": shared_meta,
                    "tab": active_tab,
                    "radar": selected_tab_data["radar"],
                    "current_term": selected_tab_data["current_term"],
                },
                {"radar": ""}
            )
            
            # Combine results
            overview_response = {
                "tabs": [{
                    "id": active_tab,
                    "summary": summary_response.get("summary", ""),
                    "trend": trend_response.get("trend", ""),
                    "subjects": subjects_response.get("subjects", ""),
                    "radar": radar_response.get("radar", ""),
                }]
            }
    elif active_tab == "Tá»• Há»£p":
        # Analyze exam blocks
        exam_instructions = build_exam_blocks_instructions()
        exam_schema = {"headline": "", "blocks": [{"id": "", "comment": ""}]}
        exam_response = await ask_llm_for_group(
            "ÄÃ¡nh giÃ¡ khá»‘i thi",
            exam_instructions,
            {"meta": shared_meta, **exam_blocks_payload},
            exam_schema,
        )
    elif active_tab == "Tá»«ng MÃ´n":
        # Analyze individual subjects
        logger.info(f"[AI_ANALYSIS] Processing tab: Tá»«ng MÃ´n, subjects count: {len(subject_payload)}")
        subject_instructions = build_individual_subjects_instructions()
        subject_schema = {"subjects": [{"id": "", "comment": ""}]}
        subject_response = await ask_llm_for_group(
            "Nháº­n xÃ©t tá»«ng mÃ´n",
            subject_instructions,
            {"meta": shared_meta, "subjects": subject_payload},
            subject_schema,
        )
        logger.info(f"[AI_ANALYSIS] Got subject_response with keys: {list(subject_response.keys()) if subject_response else 'empty'}")
    # Note: If active_tab is unknown, all responses remain empty (default behavior)

    ai_response = {
        "overview_tabs": overview_response.get("tabs"),
        "exam_blocks": exam_response,
        "subjects": subject_response.get("subjects"),
    }

    def index_by_id(items: object) -> Dict[str, Dict[str, object]]:
        mapping: Dict[str, Dict[str, object]] = {}
        if isinstance(items, list):
            for item in items:
                if isinstance(item, dict):
                    key = item.get("id")
                    if isinstance(key, str):
                        mapping[key] = item
        return mapping

    def pick_text(primary: object, fallback: object) -> str | None:
        if isinstance(primary, str) and primary.strip():
            return primary.strip()
        if isinstance(fallback, str) and fallback.strip():
            return fallback.strip()
        return None

    overview_ai_map = index_by_id(ai_response.get("overview_tabs"))
    exam_ai = ai_response.get("exam_blocks") if isinstance(ai_response.get("exam_blocks"), dict) else {}
    exam_block_ai_map = index_by_id(exam_ai.get("blocks")) if isinstance(exam_ai, dict) else {}
    subject_ai_map = index_by_id(ai_response.get("subjects"))

    # Build overview comments from AI response
    overview_llm: Dict[str, Dict[str, str]] = {}
    for tab_name in ["Chung", "Khá»‘i TN", "Khá»‘i XH"]:
        ai_section = overview_ai_map.get(tab_name, {})
        overview_llm[tab_name] = {
            "summary": ai_section.get("summary", ""),
            "trend": ai_section.get("trend", ""),
            "subjects": ai_section.get("subjects", ""),
            "radar": ai_section.get("radar", ""),
        }

    exam_headline_text = ""
    if isinstance(exam_ai, dict):
        exam_headline_text = exam_ai.get("headline", "")

    exam_block_llm: Dict[str, Dict[str, str]] = {}
    for block in EXAM_BLOCKS.keys():
        block_payload = exam_block_ai_map.get(block, {})
        exam_block_llm[block] = {
            "comment": block_payload.get("comment", "")
        }

    subject_llm: Dict[str, Dict[str, str]] = {}
    for subject in SUBJECTS:
        ai_comment = subject_ai_map.get(subject, {}).get("comment", "")
        subject_llm[subject] = {
            "comment": ai_comment
        }

    warning = None
    if actual_count < 5:
        warning = {"level": "danger", "message": "ChÆ°a Ä‘á»§ thÃ´ng tin Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n"}
    elif 5 <= actual_count <= 20:
        warning = {"level": "info", "message": "KNN Ä‘Ã£ kÃ­ch hoáº¡t â€” bá»• sung cÃ ng nhiá»u Ä‘iá»ƒm Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c"}

    resp = {
        "user_id": user_id,
        "generated_at": datetime.utcnow().isoformat(),
        "comments_version": 3,
        "slide_comments": {
            "overview": {
                name: {
                    "narrative": overview_llm.get(name),
                }
                for name in ["Chung", "Khá»‘i TN", "Khá»‘i XH"]
            },
            "exam_blocks": {
                "headline": {
                    "narrative": {"headline": exam_headline_text} if exam_headline_text else None,
                },
                "blocks": {
                    block: {
                        "narrative": exam_block_llm.get(block),
                    }
                    for block in EXAM_BLOCKS.keys()
                },
            },
            "subjects": {
                subject: {
                    "narrative": subject_llm.get(subject),
                }
                for subject in SUBJECTS
            },
        },
    }
    if warning is not None:
        resp["warning"] = warning
    
    # Persist to database if requested
    if payload.persist:
        try:
            # Save overview insights
            for tab_name in ["Chung", "Khá»‘i TN", "Khá»‘i XH"]:
                tab_data = overview_llm.get(tab_name, {})
                if tab_data.get("overview"):
                    insight = (
                        db.query(models.AIInsight)
                        .filter(
                            models.AIInsight.user_id == user_id,
                            models.AIInsight.insight_type == "slide_comment",
                            models.AIInsight.context_key == f"overview_{tab_name}"
                        )
                        .first()
                    )
                    if insight:
                        insight.content = tab_data["overview"]
                        insight.updated_at = datetime.utcnow()
                    else:
                        insight = models.AIInsight(
                            user_id=user_id,
                            insight_type="slide_comment",
                            context_key=f"overview_{tab_name}",
                            content=tab_data["overview"],
                            metadata_={"tab": tab_name, "version": 3}
                        )
                        db.add(insight)
            
            # Save exam block insights
            for block, block_data in exam_block_llm.items():
                if block_data.get("comment"):
                    insight = (
                        db.query(models.AIInsight)
                        .filter(
                            models.AIInsight.user_id == user_id,
                            models.AIInsight.insight_type == "slide_comment",
                            models.AIInsight.context_key == f"exam_block_{block}"
                        )
                        .first()
                    )
                    if insight:
                        insight.content = block_data["comment"]
                        insight.updated_at = datetime.utcnow()
                    else:
                        insight = models.AIInsight(
                            user_id=user_id,
                            insight_type="slide_comment",
                            context_key=f"exam_block_{block}",
                            content=block_data["comment"],
                            metadata_={"block": block, "version": 3}
                        )
                        db.add(insight)
            
            # Save subject insights
            for subject, subject_data in subject_llm.items():
                if subject_data.get("comment"):
                    insight = (
                        db.query(models.AIInsight)
                        .filter(
                            models.AIInsight.user_id == user_id,
                            models.AIInsight.insight_type == "slide_comment",
                            models.AIInsight.context_key == f"subject_{subject}"
                        )
                        .first()
                    )
                    if insight:
                        insight.content = subject_data["comment"]
                        insight.updated_at = datetime.utcnow()
                    else:
                        insight = models.AIInsight(
                            user_id=user_id,
                            insight_type="slide_comment",
                            context_key=f"subject_{subject}",
                            content=subject_data["comment"],
                            metadata_={"subject": subject, "version": 3}
                        )
                        db.add(insight)
            
            db.commit()
            logger.info(f"[AI_INSIGHTS] Persisted slide comments to database for user {user_id}")
        except Exception as e:
            logger.error(f"[AI_INSIGHTS] Failed to persist to database: {e}")
            db.rollback()
    
    return JSONResponse(content=resp)
